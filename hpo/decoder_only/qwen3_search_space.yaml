experiment:
  name: qwen3_lora_hpo
  n_trials: 16
  seed: 123

base_config: configs/decoder_only/axolotl/qwen3_lora.yaml
output_root: outputs/hpo/decoder_only/qwen3
generated_config_dir: hpo/decoder_only/generated_configs
manifest_path: hpo/decoder_only/qwen3_trials_manifest.csv
run_status_path: hpo/decoder_only/qwen3_run_status.csv

fixed_overrides:
  logging_steps: 50
  eval_steps: 1000
  save_steps: 1000
  save_total_limit: 1
  load_best_model_at_end: true
  metric_for_best_model: eval_loss
  greater_is_better: false

search_space:
  learning_rate:
    type: float
    low: 3.0e-5
    high: 3.0e-4
    log: true
  lora_r:
    type: categorical
    choices: [8, 16, 32]
  lora_alpha:
    type: categorical
    choices: [16, 32, 64]
  lora_dropout:
    type: categorical
    choices: [0.0, 0.05, 0.1]
  micro_batch_size:
    type: categorical
    choices: [4, 8, 10]
  gradient_accumulation_steps:
    type: categorical
    choices: [2, 4, 8]
  warmup_steps:
    type: categorical
    choices: [100, 200, 500]
  max_steps:
    type: categorical
    choices: [20000, 40000, 80000]
