{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80399a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names, get_dataset_split_names\n",
    "import duckdb, pandas as pd, pathlib, gc\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from cleantext import clean\n",
    "import os, nltk\n",
    "import os, nltk, re\n",
    "from bs4 import BeautifulSoup\n",
    "import hashlib\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "DB_PATH = '../data/duckdb/subs.duckdb'\n",
    "TABLE   = 'ptbrvarid'   # raw goes here, as you requested\n",
    "BATCH   = 20_000\n",
    "NLTK_USER_DIR = os.path.expanduser(\"~/nltk_data\")\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "NLTK_USER_DIR = os.path.expanduser(\"~/nltk_data\")\n",
    "if NLTK_USER_DIR not in nltk.data.path:\n",
    "    nltk.data.path.append(NLTK_USER_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb72c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing domain: journalistic\n",
      "  Processing split: train\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, get_dataset_config_names, get_dataset_split_names\n",
    "import duckdb, pandas as pd, pathlib, gc\n",
    "\n",
    "DB_PATH = '../data/duckdb/subs.duckdb'\n",
    "TABLE   = 'ptbrvarid'   # raw goes here, as you requested\n",
    "BATCH   = 20_000\n",
    "\n",
    "with duckdb.connect(DB_PATH) as con:\n",
    "    con.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS ptbrvarid (\n",
    "        dataset     TEXT,\n",
    "        domain      TEXT,\n",
    "        split       TEXT,\n",
    "        label       TEXT,           -- 'pt-BR' | 'pt-PT'\n",
    "        text_pt_br  TEXT,\n",
    "        text_pt_pt  TEXT\n",
    "    );\n",
    "    \"\"\")\n",
    "    # keep only RAW rows scoped by dataset tag so we can also store processed later\n",
    "    con.execute(\"DELETE FROM ptbrvarid WHERE dataset='PtBrVId-Raw'\")\n",
    "\n",
    "def ingest_ptbrvid_raw():\n",
    "    with duckdb.connect(DB_PATH) as con:\n",
    "        for domain in get_dataset_config_names('liaad/PtBrVId-Raw'):\n",
    "            print(f\"Processing domain: {domain}\")\n",
    "            for split in get_dataset_split_names('liaad/PtBrVId-Raw', domain):\n",
    "                print(f\"  Processing split: {split}\")\n",
    "                ds  = load_dataset('liaad/PtBrVId-Raw', domain, split=split, streaming=True)\n",
    "                buf = []; n_in = n_new = 0\n",
    "                for ex in ds:\n",
    "                    lbl = 'pt-BR' if ex['label'] == 1 else 'pt-PT'\n",
    "                    br  = ex['text'] if lbl == 'pt-BR' else None\n",
    "                    pt  = ex['text'] if lbl == 'pt-PT' else None\n",
    "                    buf.append(('PtBrVId-Raw', domain, split, lbl, br, pt))\n",
    "                    n_in += 1\n",
    "                    if len(buf) >= BATCH:\n",
    "                        df = pd.DataFrame(buf, columns=['dataset','domain','split','label','text_pt_br','text_pt_pt'])\n",
    "                        con.register('buf', df)\n",
    "                        con.execute(\"INSERT INTO ptbrvarid SELECT * FROM buf\")\n",
    "                        con.unregister('buf'); n_new += len(buf); buf.clear(); gc.collect()\n",
    "                if buf:\n",
    "                    df = pd.DataFrame(buf, columns=['dataset','domain','split','label','text_pt_br','text_pt_pt'])\n",
    "                    con.register('buf', df)\n",
    "                    con.execute(\"INSERT INTO ptbrvarid SELECT * FROM buf\")\n",
    "                    con.unregister('buf'); n_new += len(buf); buf.clear(); gc.collect()\n",
    "                print(f\"✓ {domain}/{split}: read {n_in:,}, wrote {n_new:,}\")\n",
    "\n",
    "ingest_ptbrvid_raw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b17d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_punkt():\n",
    "    \"\"\"\n",
    "    Ensure Portuguese punkt is available and visible to this kernel.\n",
    "    Newer NLTK may also require 'punkt_tab'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/punkt/portuguese.pickle\")\n",
    "    except LookupError:\n",
    "        # download into the same directory we added to nltk.data.path\n",
    "        nltk.download(\"punkt\", download_dir=NLTK_USER_DIR, quiet=True)\n",
    "        try:\n",
    "            nltk.data.find(\"tokenizers/punkt/portuguese.pickle\")\n",
    "        except LookupError:\n",
    "            nltk.download(\"punkt_tab\", download_dir=NLTK_USER_DIR, quiet=True)\n",
    "            nltk.data.find(\"tokenizers/punkt/portuguese.pickle\")\n",
    "\n",
    "# ----------------------------\n",
    "# Author's regex & helpers (verbatim)\n",
    "# ----------------------------\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import hashlib\n",
    "\n",
    "HTML_RE = re.compile(r\"<[^>]+>\")\n",
    "URL_RE = re.compile(r\"((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#…])*\")\n",
    "HASHTAG_RE = re.compile(r\"#(\\w+)\")\n",
    "QUOTE_SPACE_START_RE = re.compile(r\"^\\\"\\s\")\n",
    "QUOTE_SPACE_END_RE = re.compile(r\"\\s\\\"$\")\n",
    "MENTION_RE = re.compile(r\"@(\\w+)\")\n",
    "RETWEET_RE = re.compile(r\"RT @(\\w+):\")\n",
    "COD_RE = re.compile(r\"COD _ (\\w+) \")\n",
    "BULLET_RE = re.compile(r\"^(\\d)+.\\s\")\n",
    "THREE_DASH_RE = re.compile(r\"---.*---\")\n",
    "MORE_THAN_THREE_POINTS_RE = re.compile(r\"\\.{4,}\")\n",
    "MODE = \"ptbrvarid\"   # options: \"ptbrvarid\" | \"ptradutor\"\n",
    "\n",
    "\n",
    "VALID_CHARS = \"0123456789abcdefghijklmnopqrstuvwxyzàáâãåāèéêëěėēîïíìįīĵłñńôöòóōõšśûüùúūÿýźçćčñń!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~«»“”ºª€ \\t\\n\\r\\x0b\\x0c\"\n",
    "\n",
    "INVALID_START = [\n",
    "    \"List of recent changes\",\"Sort by\",\"Home |\",\"> Home\",\"useful tips\",\"Licenses:\",\"Search in: \",\n",
    "    \"Terms of Use - \",\"Home page\",\"Home Page\",\"Copyright\",\"Results/Page\",\n",
    "    \"!\",\"#\",\"$\",\"%\",\"&\",\"*\",\"+\",\n",
    "    \",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\"=\",\n",
    "    \">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\"`\",\"{\",\"|\",\"}\",\"~\",\n",
    "]\n",
    "INVALID_MIDDLE = [\" @ \", \" / \", \" | \", \"[...]\", \"(...)\"]\n",
    "INVALID_END = [\" (\"]\n",
    "\n",
    "MONTHS = [\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\"]\n",
    "SPEAKER_LABEL_SINGLE_LETTER = re.compile(\n",
    "    r'(?m)(^|\\s|[(\\[\"“])'          # \\1 = boundary we preserve\n",
    "    r'[A-Za-zÀ-ÖØ-öø-ÿ]\\.'         # exactly one letter + dot\n",
    "    r'\\s*(?:--|[-–—]{1,2})\\s*'     # \"--\" or one/two dashes (hyphen/en/em), with spaces\n",
    ")\n",
    "\n",
    "# Word followed by double hyphen (speaker label), preserving the boundary before it\n",
    "SPEAKER_LABEL_WORD_DASH = re.compile(\n",
    "    r'(?m)(^|\\s)[A-Za-zÀ-ÖØ-öø-ÿ]+(?:\\.)?\\s+--\\s*'\n",
    ")\n",
    "\n",
    "# Dialogue-leading double dash right after strong punctuation or line start\n",
    "DIALOGUE_LEADING_DASH = re.compile(\n",
    "    r'(?m)(^|[\\.!\\?\\:\\;…])\\s*--\\s*'\n",
    ")\n",
    "\n",
    "# Capitalize the first letter after strong punctuation or at start of text/line.\n",
    "# Keeps any opening quotes/brackets just before the letter.\n",
    "CAP_SENT_START = re.compile(\n",
    "    r'(?m)(^|[\\.!\\?\\:\\;…]\\s+)([\\\"\\'“”«»\\(\\[\\{]*)([a-zà-öø-ÿ])'\n",
    ")\n",
    "\n",
    "\n",
    "def remove_html_tags(text): return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "def remove_hashtags(text): return HASHTAG_RE.sub(\"\", text).strip()\n",
    "def remove_mentions(text): return MENTION_RE.sub(\"\", text).strip()\n",
    "def remove_retweets(text): return RETWEET_RE.sub(\"\", text).strip()\n",
    "def remove_urls(text): return URL_RE.sub(\"\", text).strip()\n",
    "def remove_cod_literature(text): return COD_RE.sub(\"\", text).strip()\n",
    "def remove_bullets(text): return BULLET_RE.sub(\"\", text).strip()\n",
    "def remove_three_dashes(text): return THREE_DASH_RE.sub(\"\", text).strip()\n",
    "def remove_quote_space_start(text): return QUOTE_SPACE_START_RE.sub('\"', text)\n",
    "def remove_quote_space_end(text):\n",
    "    if text.endswith(' \"'): return text[:-2] + '\"'\n",
    "    return text\n",
    "def has_more_than_three_points(text): return bool(MORE_THAN_THREE_POINTS_RE.search(text))\n",
    "def starts_with_month(text): return text.lower().startswith(tuple(MONTHS))\n",
    "def has_too_long_word(text): return any(word for word in text.split(\" \") if len(word) > 20)\n",
    "def has_invalid_start(text): return text.startswith(tuple(INVALID_START))\n",
    "def has_invalid_middle(text): return any(True for word in INVALID_MIDDLE if word in text)\n",
    "def has_invalid_end(text): return text.endswith(tuple(INVALID_END))\n",
    "def has_valid_brackets(text): return (text.count(\"(\")==text.count(\")\") and text.count(\"[\")==text.count(\"]\") and text.count(\"{\")==text.count(\"}\"))\n",
    "def has_valid_quotes(text): return text.count('\"') % 2 == 0 and text.count(\"“\")==text.count(\"”\")\n",
    "def is_empty(text): return len(text) == 0\n",
    "def has_invalid_character(text):\n",
    "    for char in text:\n",
    "        if char.lower() not in VALID_CHARS: return True\n",
    "    return False\n",
    "\n",
    "def normalize_double_quotes(text: str) -> str:\n",
    "    if not text: return text\n",
    "    return (text.replace(\"«\", '\"').replace(\"»\", '\"')\n",
    "                .replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "                .replace(\"„\", '\"'))\n",
    "\n",
    "def remove_single_letter_speaker_labels(text: str) -> str:\n",
    "    if not text: return text\n",
    "    return SPEAKER_LABEL_SINGLE_LETTER.sub(r\"\\1\", text)\n",
    "\n",
    "def remove_speaker_label_word_dash(text: str) -> str:\n",
    "    if not text: return text\n",
    "    return SPEAKER_LABEL_WORD_DASH.sub(r'\\1', text)\n",
    "\n",
    "def remove_dialogue_leading_double_dash(text: str) -> str:\n",
    "    if not text: return text\n",
    "    return DIALOGUE_LEADING_DASH.sub(lambda m: (m.group(1) or '') + ' ', text)\n",
    "\n",
    "def capitalize_sentence_starts(text: str) -> str:\n",
    "    if not text: return text\n",
    "    m = re.match(r'^([\\\"\\'“”«»\\(\\[\\{]*)([a-zà-öø-ÿ])', text)\n",
    "    if m: text = m.group(1) + m.group(2).upper() + text[m.end():]\n",
    "    def repl(m): return (m.group(1) or '') + (m.group(2) or '') + m.group(3).upper()\n",
    "    return CAP_SENT_START.sub(repl, text)\n",
    "\n",
    "def author_transform_chain(text: str) -> str:\n",
    "    text = remove_retweets(text); text = remove_mentions(text); text = remove_hashtags(text)\n",
    "    text = remove_urls(text); text = remove_html_tags(text); text = normalize_double_quotes(text)\n",
    "    text = remove_single_letter_speaker_labels(text); text = remove_speaker_label_word_dash(text)\n",
    "    text = remove_dialogue_leading_double_dash(text); text = remove_cod_literature(text)\n",
    "    text = remove_bullets(text); text = remove_three_dashes(text)\n",
    "    text = remove_quote_space_start(text); text = remove_quote_space_end(text)\n",
    "    text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
    "    text = capitalize_sentence_starts(text)\n",
    "    return text\n",
    "\n",
    "def drop_nans_and_empties(ds):\n",
    "    return ds.filter(lambda x: x[\"text\"] is not None and len(x[\"text\"].strip()) > 0)\n",
    "\n",
    "def drop_exact_duplicates(ds, batch_size: int = 1000):\n",
    "    seen = set()\n",
    "    def tag_batch(batch):\n",
    "        keep = []\n",
    "        for t in batch[\"text\"]:\n",
    "            h = hashlib.md5(t.encode(\"utf-8\")).hexdigest()\n",
    "            keep.append(h not in seen)\n",
    "            seen.add(h)\n",
    "        return {\"__keep__\": keep}\n",
    "    ds = ds.map(tag_batch, batched=True, batch_size=batch_size, num_proc=1)\n",
    "    ds = ds.filter(lambda k: k, input_columns=\"__keep__\").remove_columns([\"__keep__\"])\n",
    "    return ds\n",
    "\n",
    "def apply_clean_text_ascii(s: str) -> str:\n",
    "    return clean(s, fix_unicode=True, to_ascii=True, lower=False,\n",
    "                 no_line_breaks=False, no_urls=False, no_emails=False,\n",
    "                 no_phone_numbers=False, no_numbers=False, no_digits=False, no_currency_symbols=False)\n",
    "\n",
    "_FALLBACK_TOKEN_RE = re.compile(r\"\\w+|[^\\w\\s]\")\n",
    "def pt_word_count(s: str) -> int:\n",
    "    try:\n",
    "        return len(nltk.word_tokenize(s, language=\"portuguese\"))\n",
    "    except LookupError:\n",
    "        return len(_FALLBACK_TOKEN_RE.findall(s))\n",
    "\n",
    "def add_length_column(ds, batch_size: int = 1000):\n",
    "    def _lens(batch): return {\"__len__\": [pt_word_count(t) for t in batch[\"text\"]]}\n",
    "    return ds.map(_lens, batched=True, batch_size=batch_size, num_proc=1)\n",
    "\n",
    "def iqr_bounds_from_lengths(lengths):\n",
    "    q1, q3 = np.percentile(lengths, 25), np.percentile(lengths, 75)\n",
    "    iqr = q3 - q1\n",
    "    return (q1 - 1.5*iqr, q3 + 1.5*iqr)\n",
    "\n",
    "def apply_iqr_filter_on_cached_lengths(ds, lo, hi):\n",
    "    ds = ds.filter(lambda L: lo <= L <= hi, input_columns=\"__len__\")\n",
    "    return ds.remove_columns([\"__len__\"])\n",
    "\n",
    "def apply_clean_text_unicode_only(s: str) -> str:\n",
    "    return clean(s, fix_unicode=True, to_ascii=False, lower=False,\n",
    "                 no_line_breaks=False, no_urls=False, no_emails=False,\n",
    "                 no_phone_numbers=False, no_numbers=False, no_digits=False, no_currency_symbols=False)\n",
    "\n",
    "# ====== NEW: safe jusText wrapper + scope switch ======\n",
    "def safe_justext(text: str) -> str:\n",
    "    if not text: return text\n",
    "    try:\n",
    "        import justext\n",
    "        paras = justext.justext(text, justext.get_stoplist(\"Portuguese\"))\n",
    "        good = [p.text for p in paras if p.class_type == \"good\"]\n",
    "        return \"\\n\".join(good) if good else text\n",
    "    except Exception:\n",
    "        return text\n",
    "\n",
    "def web_justext(text: str,\n",
    "                *,\n",
    "                drop_if_no_good: bool = True,\n",
    "                min_chars: int = 30,\n",
    "                min_ratio: float = 0.20) -> str:\n",
    "    \"\"\"\n",
    "    Run jusText and drop rows that look like boilerplate.\n",
    "    - drop_if_no_good: drop if no 'good' paragraphs\n",
    "    - min_chars: drop if cleaned text shorter than this\n",
    "    - min_ratio: drop if cleaned/original length ratio below this\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    try:\n",
    "        import justext\n",
    "        paras = justext.justext(text, justext.get_stoplist(\"Portuguese\"))\n",
    "        good  = [p.text for p in paras if p.class_type == \"good\"]\n",
    "        if not good:\n",
    "            return \"\" if drop_if_no_good else text\n",
    "        jt = \"\\n\".join(good).strip()\n",
    "        if len(jt) < min_chars:\n",
    "            return \"\"\n",
    "        if len(jt) / max(1, len(text)) < min_ratio:\n",
    "            return \"\"\n",
    "        return jt\n",
    "    except Exception:\n",
    "        return text  # conservative on parser error\n",
    "\n",
    "def clean_one_domain_split(\n",
    "    domain: str,\n",
    "    split: str,\n",
    "    use_author_transforms: bool = True,\n",
    "    run_web_justext: bool = True,   # kept for back-compat (ignored if justext_scope is set)\n",
    "    apply_author_filters: bool = True,\n",
    "    keep_accents: bool = True,\n",
    "    num_proc: int = 1,\n",
    "    batch_size: int = 1000,\n",
    "    *,\n",
    "    justext_scope: str = \"web\",     # NEW: \"none\" | \"web\" | \"all\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Same as yours, but jusText can run on: none / web / all.\n",
    "    \"\"\"\n",
    "    ds = load_dataset(\"liaad/PtBrVId-Raw\", domain, split=split)\n",
    "    ds = drop_nans_and_empties(ds)\n",
    "\n",
    "    # --- jusText control (NEW) ---\n",
    "    scope = justext_scope or (\"web\" if run_web_justext else \"none\")\n",
    "    if scope == \"all\" or (scope == \"web\" and domain == \"web\"):\n",
    "        ds = ds.map(lambda x: {\"text\": web_justext(x[\"text\"])},\n",
    "                    num_proc=num_proc, batched=False)\n",
    "\n",
    "    # (rest of your function unchanged below…)\n",
    "    if use_author_transforms:\n",
    "        ds = ds.map(lambda x: {\"text\": author_transform_chain(x[\"text\"])},\n",
    "                    num_proc=num_proc, batched=False)\n",
    "\n",
    "    if keep_accents:\n",
    "        ds = ds.map(lambda x: {\"text\": apply_clean_text_unicode_only(x[\"text\"])},\n",
    "                    num_proc=num_proc, batched=False)\n",
    "    else:\n",
    "        ds = ds.map(lambda x: {\"text\": apply_clean_text_ascii(x[\"text\"])},\n",
    "                    num_proc=num_proc, batched=False)\n",
    "\n",
    "    ds = drop_exact_duplicates(ds, batch_size=batch_size)\n",
    "\n",
    "    if apply_author_filters:\n",
    "        ds = ds.filter(\n",
    "            lambda t: (not starts_with_month(t))\n",
    "                      and (not has_too_long_word(t))\n",
    "                      and (not has_invalid_start(t))\n",
    "                      and (not has_invalid_middle(t))\n",
    "                      and (not has_invalid_end(t))\n",
    "                      and (not has_more_than_three_points(t))\n",
    "                      and (not is_empty(t))\n",
    "                      and (not has_invalid_character(t))\n",
    "                      and has_valid_brackets(t)\n",
    "                      and has_valid_quotes(t),\n",
    "            input_columns=\"text\",\n",
    "            num_proc=num_proc\n",
    "        )\n",
    "\n",
    "    ds = add_length_column(ds, batch_size=batch_size)\n",
    "    lo, hi = iqr_bounds_from_lengths(ds[\"__len__\"])\n",
    "    ds = apply_iqr_filter_on_cached_lengths(ds, lo, hi)\n",
    "    return ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8db68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9192200f8f4b43a0951286d1c0f946ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journalistic/train: raw=1,842,804 → after_IQR=1,574,068 (85.42%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bc9c394eec4b9aad228e953f1d3ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legal/train: raw=4,302,003 → after_IQR=1,118,443 (26.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4e768466ab4eef9c23d44ba3276853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literature/train: raw=81,984 → after_IQR=39,382 (48.04%)\n",
      "politics/train: raw=34,605 → after_IQR=22,831 (65.98%)\n",
      "social_media/train: raw=2,678,580 → after_IQR=219,290 (8.19%)\n",
      "web/train: raw=133,664 → after_IQR=17,714 (13.25%)\n",
      "[DONE] Inserted processed rows with your pipeline + jusText (dataset='PtBrVId'): 0\n",
      "\n",
      "=== Per-stage counts (subset) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>split</th>\n",
       "      <th>after_nonempty</th>\n",
       "      <th>after_jusText</th>\n",
       "      <th>after_author</th>\n",
       "      <th>after_clean</th>\n",
       "      <th>after_dedup</th>\n",
       "      <th>after_filters</th>\n",
       "      <th>after_IQR</th>\n",
       "      <th>drop_empty</th>\n",
       "      <th>drop_jusText</th>\n",
       "      <th>drop_author</th>\n",
       "      <th>drop_clean</th>\n",
       "      <th>drop_dedup</th>\n",
       "      <th>drop_filters</th>\n",
       "      <th>drop_IQR</th>\n",
       "      <th>IQR_lo</th>\n",
       "      <th>IQR_hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>1842804</td>\n",
       "      <td>1717167</td>\n",
       "      <td>1717167</td>\n",
       "      <td>1717167</td>\n",
       "      <td>1717126</td>\n",
       "      <td>1607201</td>\n",
       "      <td>1574068</td>\n",
       "      <td>0</td>\n",
       "      <td>125637</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>109925</td>\n",
       "      <td>33133</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>legal</td>\n",
       "      <td>train</td>\n",
       "      <td>4302002</td>\n",
       "      <td>2110995</td>\n",
       "      <td>2110995</td>\n",
       "      <td>2110995</td>\n",
       "      <td>2099143</td>\n",
       "      <td>1189672</td>\n",
       "      <td>1118443</td>\n",
       "      <td>1</td>\n",
       "      <td>2191007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11852</td>\n",
       "      <td>909471</td>\n",
       "      <td>71229</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>122.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>literature</td>\n",
       "      <td>train</td>\n",
       "      <td>81984</td>\n",
       "      <td>59513</td>\n",
       "      <td>59513</td>\n",
       "      <td>59513</td>\n",
       "      <td>59513</td>\n",
       "      <td>40775</td>\n",
       "      <td>39382</td>\n",
       "      <td>0</td>\n",
       "      <td>22471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18738</td>\n",
       "      <td>1393</td>\n",
       "      <td>-10.5</td>\n",
       "      <td>177.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "      <td>train</td>\n",
       "      <td>34604</td>\n",
       "      <td>32427</td>\n",
       "      <td>32427</td>\n",
       "      <td>32427</td>\n",
       "      <td>32427</td>\n",
       "      <td>24425</td>\n",
       "      <td>22831</td>\n",
       "      <td>1</td>\n",
       "      <td>2177</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8002</td>\n",
       "      <td>1594</td>\n",
       "      <td>-245.0</td>\n",
       "      <td>747.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>social_media</td>\n",
       "      <td>train</td>\n",
       "      <td>2678579</td>\n",
       "      <td>266648</td>\n",
       "      <td>266645</td>\n",
       "      <td>266645</td>\n",
       "      <td>262629</td>\n",
       "      <td>220895</td>\n",
       "      <td>219290</td>\n",
       "      <td>1</td>\n",
       "      <td>2411931</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4016</td>\n",
       "      <td>41734</td>\n",
       "      <td>1605</td>\n",
       "      <td>22.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>web</td>\n",
       "      <td>train</td>\n",
       "      <td>133664</td>\n",
       "      <td>101401</td>\n",
       "      <td>101401</td>\n",
       "      <td>101401</td>\n",
       "      <td>101367</td>\n",
       "      <td>18949</td>\n",
       "      <td>17714</td>\n",
       "      <td>0</td>\n",
       "      <td>32263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>82418</td>\n",
       "      <td>1235</td>\n",
       "      <td>-189.5</td>\n",
       "      <td>502.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain  split  after_nonempty  after_jusText  after_author  \\\n",
       "0  journalistic  train         1842804        1717167       1717167   \n",
       "1         legal  train         4302002        2110995       2110995   \n",
       "2    literature  train           81984          59513         59513   \n",
       "3      politics  train           34604          32427         32427   \n",
       "4  social_media  train         2678579         266648        266645   \n",
       "5           web  train          133664         101401        101401   \n",
       "\n",
       "   after_clean  after_dedup  after_filters  after_IQR  drop_empty  \\\n",
       "0      1717167      1717126        1607201    1574068           0   \n",
       "1      2110995      2099143        1189672    1118443           1   \n",
       "2        59513        59513          40775      39382           0   \n",
       "3        32427        32427          24425      22831           1   \n",
       "4       266645       262629         220895     219290           1   \n",
       "5       101401       101367          18949      17714           0   \n",
       "\n",
       "   drop_jusText  drop_author  drop_clean  drop_dedup  drop_filters  drop_IQR  \\\n",
       "0        125637            0           0          41        109925     33133   \n",
       "1       2191007            0           0       11852        909471     71229   \n",
       "2         22471            0           0           0         18738      1393   \n",
       "3          2177            0           0           0          8002      1594   \n",
       "4       2411931            3           0        4016         41734      1605   \n",
       "5         32263            0           0          34         82418      1235   \n",
       "\n",
       "   IQR_lo  IQR_hi  \n",
       "0   -54.0   298.0  \n",
       "1    -1.5   122.5  \n",
       "2   -10.5   177.5  \n",
       "3  -245.0   747.0  \n",
       "4    22.0    70.0  \n",
       "5  -189.5   502.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Domain totals ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>raw</th>\n",
       "      <th>after_nonempty</th>\n",
       "      <th>after_jusText</th>\n",
       "      <th>after_author</th>\n",
       "      <th>after_clean</th>\n",
       "      <th>after_dedup</th>\n",
       "      <th>after_filters</th>\n",
       "      <th>after_IQR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>legal</td>\n",
       "      <td>4302003.0</td>\n",
       "      <td>4302002.0</td>\n",
       "      <td>2110995.0</td>\n",
       "      <td>2110995.0</td>\n",
       "      <td>2110995.0</td>\n",
       "      <td>2099143.0</td>\n",
       "      <td>1189672.0</td>\n",
       "      <td>1118443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>2678580.0</td>\n",
       "      <td>2678579.0</td>\n",
       "      <td>266648.0</td>\n",
       "      <td>266645.0</td>\n",
       "      <td>266645.0</td>\n",
       "      <td>262629.0</td>\n",
       "      <td>220895.0</td>\n",
       "      <td>219290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journalistic</td>\n",
       "      <td>1842804.0</td>\n",
       "      <td>1842804.0</td>\n",
       "      <td>1717167.0</td>\n",
       "      <td>1717167.0</td>\n",
       "      <td>1717167.0</td>\n",
       "      <td>1717126.0</td>\n",
       "      <td>1607201.0</td>\n",
       "      <td>1574068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>web</td>\n",
       "      <td>133664.0</td>\n",
       "      <td>133664.0</td>\n",
       "      <td>101401.0</td>\n",
       "      <td>101401.0</td>\n",
       "      <td>101401.0</td>\n",
       "      <td>101367.0</td>\n",
       "      <td>18949.0</td>\n",
       "      <td>17714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>literature</td>\n",
       "      <td>81984.0</td>\n",
       "      <td>81984.0</td>\n",
       "      <td>59513.0</td>\n",
       "      <td>59513.0</td>\n",
       "      <td>59513.0</td>\n",
       "      <td>59513.0</td>\n",
       "      <td>40775.0</td>\n",
       "      <td>39382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>34605.0</td>\n",
       "      <td>34604.0</td>\n",
       "      <td>32427.0</td>\n",
       "      <td>32427.0</td>\n",
       "      <td>32427.0</td>\n",
       "      <td>32427.0</td>\n",
       "      <td>24425.0</td>\n",
       "      <td>22831.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         domain        raw  after_nonempty  after_jusText  after_author  \\\n",
       "0         legal  4302003.0       4302002.0      2110995.0     2110995.0   \n",
       "1  social_media  2678580.0       2678579.0       266648.0      266645.0   \n",
       "2  journalistic  1842804.0       1842804.0      1717167.0     1717167.0   \n",
       "3           web   133664.0        133664.0       101401.0      101401.0   \n",
       "4    literature    81984.0         81984.0        59513.0       59513.0   \n",
       "5      politics    34605.0         34604.0        32427.0       32427.0   \n",
       "\n",
       "   after_clean  after_dedup  after_filters  after_IQR  \n",
       "0    2110995.0    2099143.0      1189672.0  1118443.0  \n",
       "1     266645.0     262629.0       220895.0   219290.0  \n",
       "2    1717167.0    1717126.0      1607201.0  1574068.0  \n",
       "3     101401.0     101367.0        18949.0    17714.0  \n",
       "4      59513.0      59513.0        40775.0    39382.0  \n",
       "5      32427.0      32427.0        24425.0    22831.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================\n",
    "# STEP 2 + METRICS (single pass per domain/split with on-disk staging)\n",
    "# - Applies jusText on ALL domains (and really drops boilerplate)\n",
    "# - Writes final rows into ptbrvarid (dataset='PtBrVId')\n",
    "# - Writes per-stage counts into ptbrvarid_metrics\n",
    "# =============================\n",
    "from datasets import load_dataset, get_dataset_config_names, get_dataset_split_names\n",
    "import duckdb, pandas as pd, numpy as np, hashlib, warnings, re\n",
    "from bs4 import MarkupResemblesLocatorWarning\n",
    "warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
    "\n",
    "DB_PATH = \"../data/duckdb/subs.duckdb\"\n",
    "BATCH_ROWS = 20_000\n",
    "\n",
    "# -------- jusText that actually prunes --------\n",
    "\n",
    "\n",
    "# -------- tiny helper: your heuristic predicate --------\n",
    "def _pass_filters(t: str) -> bool:\n",
    "    return (not starts_with_month(t)\n",
    "            and not has_too_long_word(t)\n",
    "            and not has_invalid_start(t)\n",
    "            and not has_invalid_middle(t)\n",
    "            and not has_invalid_end(t)\n",
    "            and not has_more_than_three_points(t)\n",
    "            and not is_empty(t)\n",
    "            and not has_invalid_character(t)\n",
    "            and has_valid_brackets(t)\n",
    "            and has_valid_quotes(t))\n",
    "\n",
    "# -------- DB setup --------\n",
    "with duckdb.connect(DB_PATH) as con:\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS ptbrvarid (\n",
    "            dataset     TEXT,\n",
    "            domain      TEXT,\n",
    "            split       TEXT,\n",
    "            label       TEXT,\n",
    "            text_pt_br  TEXT,\n",
    "            text_pt_pt  TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS ptbrvarid_metrics (\n",
    "            dataset     TEXT,\n",
    "            domain      TEXT,\n",
    "            split       TEXT,\n",
    "            raw                 BIGINT,\n",
    "            after_nonempty      BIGINT,\n",
    "            after_jusText       BIGINT,\n",
    "            after_author        BIGINT,\n",
    "            after_clean         BIGINT,\n",
    "            after_dedup         BIGINT,\n",
    "            after_filters       BIGINT,\n",
    "            after_IQR           BIGINT,\n",
    "            drop_empty          BIGINT,\n",
    "            drop_jusText        BIGINT,\n",
    "            drop_author         BIGINT,\n",
    "            drop_clean          BIGINT,\n",
    "            drop_dedup          BIGINT,\n",
    "            drop_filters        BIGINT,\n",
    "            drop_IQR            BIGINT,\n",
    "            IQR_lo              DOUBLE,\n",
    "            IQR_hi              DOUBLE\n",
    "        )\n",
    "    \"\"\")\n",
    "    # Clear previous processed rows + metrics for a clean rebuild\n",
    "    con.execute(\"DELETE FROM ptbrvarid WHERE dataset='PtBrVId'\")\n",
    "    con.execute(\"DELETE FROM ptbrvarid_metrics WHERE dataset='PtBrVId'\")\n",
    "\n",
    "def _safe_tbl(name: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9_]\", \"_\", name)\n",
    "\n",
    "def process_domain_split(domain: str, split: str,\n",
    "                         *, keep_accents: bool = True,\n",
    "                         use_author_transforms: bool = True,\n",
    "                         apply_author_filters: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Single (domain, split) processing:\n",
    "      Pass 1: stream RAW -> jusText -> author -> clean (accents kept) -> de-dup -> filters\n",
    "              write (label, cleaned_text, len_tokens) to stage table on disk\n",
    "              collect per-stage counters\n",
    "      Compute IQR from stage lengths\n",
    "      Insert survivors into ptbrvarid\n",
    "      Save metrics, drop stage table\n",
    "    \"\"\"\n",
    "    stage = f\"__ptbr_stage_{_safe_tbl(domain)}_{_safe_tbl(split)}\"\n",
    "    with duckdb.connect(DB_PATH) as con:\n",
    "        con.execute(f\"DROP TABLE IF EXISTS {stage}\")\n",
    "        con.execute(f\"\"\"\n",
    "            CREATE TABLE {stage} (\n",
    "                domain TEXT,\n",
    "                split  TEXT,\n",
    "                label  TEXT,\n",
    "                text   TEXT,\n",
    "                len_tokens BIGINT\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "    raw_n = n_nonempty = n_after_jt = n_after_author = n_after_clean = n_after_dedup = n_after_filters = 0\n",
    "    seen, buf = set(), []\n",
    "\n",
    "    # ---------- PASS 1: build stage ----------\n",
    "    ds = load_dataset(\"liaad/PtBrVId-Raw\", domain, split=split, streaming=True)\n",
    "    for ex in ds:\n",
    "        raw_n += 1\n",
    "        t = (ex[\"text\"] or \"\").strip()\n",
    "        if not t:\n",
    "            continue\n",
    "        n_nonempty += 1\n",
    "\n",
    "        # jusText on ALL domains; now actually drops boilerplate\n",
    "        t = web_justext(t)\n",
    "        if not t:\n",
    "            continue\n",
    "        n_after_jt += 1\n",
    "\n",
    "        if use_author_transforms:\n",
    "            t = author_transform_chain(t)\n",
    "            if not t:\n",
    "                continue\n",
    "        n_after_author += 1\n",
    "\n",
    "        t = apply_clean_text_unicode_only(t) if keep_accents else apply_clean_text_ascii(t)\n",
    "        t = (t or \"\").strip()\n",
    "        if not t:\n",
    "            continue\n",
    "        n_after_clean += 1\n",
    "\n",
    "        h = hashlib.md5(t.encode(\"utf-8\")).hexdigest()\n",
    "        if h in seen:\n",
    "            continue\n",
    "        seen.add(h)\n",
    "        n_after_dedup += 1\n",
    "\n",
    "        if apply_author_filters and (not _pass_filters(t)):\n",
    "            continue\n",
    "        n_after_filters += 1\n",
    "\n",
    "        L = pt_word_count(t)\n",
    "        lbl = 'pt-BR' if ex['label'] == 1 else 'pt-PT'\n",
    "        buf.append((domain, split, lbl, t, int(L)))\n",
    "\n",
    "        if len(buf) >= BATCH_ROWS:\n",
    "            with duckdb.connect(DB_PATH) as con:\n",
    "                con.executemany(f\"INSERT INTO {stage} VALUES (?,?,?,?,?)\", buf)\n",
    "            buf.clear()\n",
    "    if buf:\n",
    "        with duckdb.connect(DB_PATH) as con:\n",
    "            con.executemany(f\"INSERT INTO {stage} VALUES (?,?,?,?,?)\", buf)\n",
    "        buf.clear()\n",
    "\n",
    "    # If nothing survived pre-IQR, write metrics and return\n",
    "    with duckdb.connect(DB_PATH) as con:\n",
    "        n_stage = con.execute(f\"SELECT COUNT(*) FROM {stage}\").fetchone()[0]\n",
    "        if n_stage == 0:\n",
    "            metrics_row = ('PtBrVId', domain, split,\n",
    "                           raw_n, n_nonempty, n_after_jt, n_after_author, n_after_clean,\n",
    "                           n_after_dedup, n_after_filters, 0,\n",
    "                           raw_n-n_nonempty, n_nonempty-n_after_jt, n_after_jt-n_after_author,\n",
    "                           n_after_author-n_after_clean, n_after_clean-n_after_dedup,\n",
    "                           n_after_dedup-n_after_filters, n_after_filters-0,\n",
    "                           0.0, 0.0)\n",
    "            con.execute(\"\"\"\n",
    "                INSERT INTO ptbrvarid_metrics (\n",
    "                    dataset, domain, split,\n",
    "                    raw, after_nonempty, after_jusText, after_author, after_clean,\n",
    "                    after_dedup, after_filters, after_IQR,\n",
    "                    drop_empty, drop_jusText, drop_author, drop_clean, drop_dedup, drop_filters, drop_IQR,\n",
    "                    IQR_lo, IQR_hi\n",
    "                ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\n",
    "            \"\"\", metrics_row)\n",
    "            con.execute(f\"DROP TABLE {stage}\")\n",
    "            print(f\"{domain}/{split}: raw={raw_n:,} → after_IQR=0 (0.0%)\")\n",
    "            return\n",
    "\n",
    "        # Compute IQR bounds on lengths\n",
    "        q1, q3 = con.execute(\n",
    "            f\"SELECT quantile_cont(len_tokens,0.25), quantile_cont(len_tokens,0.75) FROM {stage}\"\n",
    "        ).fetchone()\n",
    "        iqr = q3 - q1\n",
    "        lo = float(q1 - 1.5 * iqr)\n",
    "        hi = float(q3 + 1.5 * iqr)\n",
    "\n",
    "        # Survivors count\n",
    "        n_after_iqr = con.execute(\n",
    "            f\"SELECT COUNT(*) FROM {stage} WHERE len_tokens BETWEEN ? AND ?\", [lo, hi]\n",
    "        ).fetchone()[0]\n",
    "\n",
    "        # Insert final rows into ptbrvarid\n",
    "        con.execute(f\"\"\"\n",
    "            INSERT INTO ptbrvarid\n",
    "            SELECT\n",
    "              'PtBrVId' AS dataset,\n",
    "              domain, split, label,\n",
    "              CASE WHEN label='pt-BR' THEN text ELSE NULL END AS text_pt_br,\n",
    "              CASE WHEN label='pt-PT' THEN text ELSE NULL END AS text_pt_pt\n",
    "            FROM {stage}\n",
    "            WHERE len_tokens BETWEEN ? AND ?\n",
    "        \"\"\", [lo, hi])\n",
    "\n",
    "        # Metrics row (FIXED: 20 placeholders + explicit columns)\n",
    "        metrics_row = ('PtBrVId', domain, split,\n",
    "                       raw_n, n_nonempty, n_after_jt, n_after_author, n_after_clean,\n",
    "                       n_after_dedup, n_after_filters, int(n_after_iqr),\n",
    "                       raw_n-n_nonempty, n_nonempty-n_after_jt, n_after_jt-n_after_author,\n",
    "                       n_after_author-n_after_clean, n_after_clean-n_after_dedup,\n",
    "                       n_after_dedup-n_after_filters, n_after_filters-int(n_after_iqr),\n",
    "                       lo, hi)\n",
    "        con.execute(\"\"\"\n",
    "            INSERT INTO ptbrvarid_metrics (\n",
    "                dataset, domain, split,\n",
    "                raw, after_nonempty, after_jusText, after_author, after_clean,\n",
    "                after_dedup, after_filters, after_IQR,\n",
    "                drop_empty, drop_jusText, drop_author, drop_clean, drop_dedup, drop_filters, drop_IQR,\n",
    "                IQR_lo, IQR_hi\n",
    "            ) VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\n",
    "        \"\"\", metrics_row)\n",
    "\n",
    "        # Drop stage\n",
    "        con.execute(f\"DROP TABLE {stage}\")\n",
    "\n",
    "        pct = round(100.0 * (n_after_iqr / max(1, raw_n)), 2)\n",
    "        print(f\"{domain}/{split}: raw={raw_n:,} → after_IQR={n_after_iqr:,} ({pct}%)\")\n",
    "\n",
    "\n",
    "# -------- Run all (domains/splits discovered from -Raw) --------\n",
    "domains = get_dataset_config_names(\"liaad/PtBrVId-Raw\")\n",
    "total_final = 0\n",
    "for d in domains:\n",
    "    splits = get_dataset_split_names(\"liaad/PtBrVId-Raw\", d)\n",
    "    for s in splits:\n",
    "        process_domain_split(d, s, keep_accents=True, use_author_transforms=True, apply_author_filters=True)\n",
    "        # add to running total\n",
    "        with duckdb.connect(DB_PATH) as con:\n",
    "            n = con.execute(\"\"\"\n",
    "                SELECT COUNT(*) FROM ptbrvarid\n",
    "                WHERE dataset='PtBrVId' AND domain=? AND split=?\n",
    "            \"\"\", [d, s]).fetchone()[0]\n",
    "            total_final += int(n)\n",
    "\n",
    "print(f\"[DONE] Inserted processed rows with your pipeline + jusText (dataset='PtBrVId'): {total_final:,}\")\n",
    "\n",
    "# -------- Nice summaries you can query later --------\n",
    "with duckdb.connect(DB_PATH, read_only=True) as con:\n",
    "    by_dom = con.execute(\"\"\"\n",
    "        SELECT domain, split, after_nonempty, after_jusText, after_author,\n",
    "               after_clean, after_dedup, after_filters, after_IQR,\n",
    "               drop_empty, drop_jusText, drop_author, drop_clean, drop_dedup, drop_filters, drop_IQR,\n",
    "               IQR_lo, IQR_hi\n",
    "        FROM ptbrvarid_metrics\n",
    "        WHERE dataset='PtBrVId'\n",
    "        ORDER BY domain, split\n",
    "    \"\"\").fetchdf()\n",
    "    print(\"\\n=== Per-stage counts (subset) ===\")\n",
    "    display(by_dom.head(20))\n",
    "\n",
    "    totals = con.execute(\"\"\"\n",
    "        SELECT domain,\n",
    "               SUM(raw)              AS raw,\n",
    "               SUM(after_nonempty)   AS after_nonempty,\n",
    "               SUM(after_jusText)    AS after_jusText,\n",
    "               SUM(after_author)     AS after_author,\n",
    "               SUM(after_clean)      AS after_clean,\n",
    "               SUM(after_dedup)      AS after_dedup,\n",
    "               SUM(after_filters)    AS after_filters,\n",
    "               SUM(after_IQR)        AS after_IQR\n",
    "        FROM ptbrvarid_metrics\n",
    "        WHERE dataset='PtBrVId'\n",
    "        GROUP BY domain\n",
    "        ORDER BY raw DESC\n",
    "    \"\"\").fetchdf()\n",
    "    print(\"\\n=== Domain totals ===\")\n",
    "    display(totals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea1f4ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "DB_PATH = \"../data/duckdb/subs.duckdb\"\n",
    "\n",
    "def _fmt_millions(x, pos):\n",
    "    return f\"{x/1_000_000:.1f}M\" if x >= 1_000_000 else f\"{int(x):,}\"\n",
    "\n",
    "# ---------- aggregate totals ----------\n",
    "with duckdb.connect(DB_PATH, read_only=True) as con:\n",
    "    tot = con.execute(\"\"\"\n",
    "      SELECT\n",
    "        SUM(raw)              AS raw,\n",
    "        SUM(after_nonempty)   AS after_nonempty,\n",
    "        SUM(after_jusText)    AS after_jusText,\n",
    "        SUM(after_dedup)      AS after_dedup,\n",
    "        SUM(after_filters)    AS after_filters,\n",
    "        SUM(after_IQR)        AS after_IQR,\n",
    "        SUM(drop_empty)       AS drop_empty,\n",
    "        SUM(drop_jusText)     AS drop_jusText,\n",
    "        SUM(drop_dedup)       AS drop_dedup,\n",
    "        SUM(drop_filters)     AS drop_filters,\n",
    "        SUM(drop_IQR)         AS drop_IQR\n",
    "      FROM ptbrvarid_metrics\n",
    "      WHERE dataset = 'PtBrVId'\n",
    "    \"\"\").fetchdf().iloc[0]\n",
    "\n",
    "# ============================================================\n",
    "# 1) Survivors after each step\n",
    "# ============================================================\n",
    "\n",
    "survivors = pd.Series({\n",
    "    \"Raw\":           int(tot[\"raw\"]),\n",
    "    \"After jusText\": int(tot[\"after_jusText\"]),\n",
    "    \"After De-dup\":  int(tot[\"after_dedup\"]),\n",
    "    \"After Filters\": int(tot[\"after_filters\"]),\n",
    "    \"After IQR\":     int(tot[\"after_IQR\"]),\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(16, 7))\n",
    "ax = plt.gca()\n",
    "bars = ax.bar(survivors.index, survivors.values)\n",
    "\n",
    "ax.set_ylabel(\"Documents\", fontsize=16)\n",
    "ax.set_title(\" \", fontsize=16)\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(_fmt_millions))\n",
    "ax.grid(axis=\"y\", linestyle=\":\", linewidth=0.8, alpha=0.6)\n",
    "\n",
    "max_val = survivors.values.max()\n",
    "ax.set_ylim(0, max_val * 1.25)\n",
    "\n",
    "for b in bars:\n",
    "    v = b.get_height()\n",
    "    ax.annotate(\n",
    "        _fmt_millions(v, None),\n",
    "        xy=(b.get_x() + b.get_width() / 2, v),\n",
    "        xytext=(0, 8),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=24,\n",
    "    )\n",
    "\n",
    "plt.xticks(rotation=0, fontsize=24)\n",
    "ax.tick_params(axis=\"y\", labelsize=24)\n",
    "plt.tight_layout()\n",
    "plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# 2) Deletions by step\n",
    "# ============================================================\n",
    "\n",
    "drops = pd.Series({\n",
    "    \"Empty\":    int(tot[\"drop_empty\"]),\n",
    "    \"jusText\":  int(tot[\"drop_jusText\"]),\n",
    "    \"De-dup\":   int(tot[\"drop_dedup\"]),\n",
    "    \"Filters\":  int(tot[\"drop_filters\"]),\n",
    "    \"IQR\":      int(tot[\"drop_IQR\"]),\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(20, 9))\n",
    "ax = plt.gca()\n",
    "bars = ax.bar(drops.index, drops.values)\n",
    "\n",
    "ax.set_ylabel(\"Documents removed\", fontsize=35)\n",
    "ax.set_title(\" \", fontsize=35)\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(_fmt_millions))\n",
    "ax.grid(axis=\"y\", linestyle=\":\", linewidth=0.8, alpha=0.6)\n",
    "\n",
    "max_val = drops.values.max()\n",
    "ax.set_ylim(0, max_val * 1.25)\n",
    "\n",
    "for b in bars:\n",
    "    v = b.get_height()\n",
    "    ax.annotate(\n",
    "        _fmt_millions(v, None),\n",
    "        xy=(b.get_x() + b.get_width() / 2, v),\n",
    "        xytext=(0, 8),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=34,\n",
    "    )\n",
    "\n",
    "plt.xticks(rotation=0, fontsize=35)\n",
    "ax.tick_params(axis=\"y\", labelsize=35)\n",
    "plt.subplots_adjust(left=0.10, right=0.98, bottom=0.22, top=0.95)\n",
    "plt.savefig(\"removals_by_step_ptbrvarid.pdf\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# 3) Per-domain view of jusText’s impact\n",
    "# ============================================================\n",
    "\n",
    "with duckdb.connect(DB_PATH, read_only=True) as con:\n",
    "    dom = con.execute(\"\"\"\n",
    "      SELECT domain,\n",
    "             SUM(after_nonempty) AS nonempty,\n",
    "             SUM(after_jusText)  AS after_jt,\n",
    "             SUM(drop_jusText)   AS drop_jt\n",
    "      FROM ptbrvarid_metrics\n",
    "      WHERE dataset = 'PtBrVId'\n",
    "      GROUP BY domain\n",
    "      ORDER BY nonempty DESC\n",
    "    \"\"\").fetchdf()\n",
    "\n",
    "plt.figure(figsize=(20, 9))\n",
    "ax = plt.gca()\n",
    "bars = ax.bar(dom[\"domain\"], dom[\"drop_jt\"])\n",
    "\n",
    "ax.set_ylabel(\"Removed by jusText\", fontsize=35)\n",
    "ax.set_title(\" \", fontsize=35)\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(_fmt_millions))\n",
    "ax.grid(axis=\"y\", linestyle=\":\", linewidth=0.8, alpha=0.6)\n",
    "\n",
    "max_val = dom[\"drop_jt\"].max()\n",
    "ax.set_ylim(0, max_val * 1.25)\n",
    "\n",
    "for b, label in zip(bars, dom[\"drop_jt\"]):\n",
    "    ax.annotate(\n",
    "        _fmt_millions(int(label), None),\n",
    "        xy=(b.get_x() + b.get_width() / 2, b.get_height()),\n",
    "        xytext=(0, 8),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=35,\n",
    "    )\n",
    "\n",
    "plt.xticks(rotation=30, ha=\"right\", fontsize=35)\n",
    "ax.tick_params(axis=\"y\", labelsize=35)\n",
    "plt.subplots_adjust(left=0.10, right=0.98, bottom=0.22, top=0.95)\n",
    "plt.savefig(\"jusText_by_domain.pdf\", dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2899c4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2991728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n\n",
       "0  2991728"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb, pandas as pd\n",
    "\n",
    "con = duckdb.connect(DB_PATH, read_only=True)\n",
    "total_rows = con.execute(\"\"\"\n",
    "-- Exact total (processed only)\n",
    "SELECT COUNT(*) AS n\n",
    "FROM ptbrvarid\n",
    "WHERE dataset = 'PtBrVId';\n",
    "\n",
    "    \"\"\").fetchdf()\n",
    "                             \n",
    "total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4967a542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/laiarodrigo/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/laiarodrigo/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK paths: ['/home/laiarodrigo/nltk_data', '/home/laiarodrigo/repos/Thesis/thesis/nltk_data', '/home/laiarodrigo/repos/Thesis/thesis/share/nltk_data', '/home/laiarodrigo/repos/Thesis/thesis/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n",
      "Has package dir?  True\n",
      "['Olá', 'mundo', '!', 'Isto', 'é', 'um', 'teste', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import os, nltk, pathlib\n",
    "\n",
    "# 1) Pick a single directory and make NLTK look there\n",
    "NLTK_USER_DIR = os.path.expanduser(\"~/nltk_data\")\n",
    "os.environ[\"NLTK_DATA\"] = NLTK_USER_DIR  # ensure child processes see it too\n",
    "if NLTK_USER_DIR not in nltk.data.path:\n",
    "    nltk.data.path.insert(0, NLTK_USER_DIR)\n",
    "\n",
    "# 2) Force-reinstall punkt + punkt_tab into that directory\n",
    "nltk.download(\"punkt\", download_dir=NLTK_USER_DIR, force=True, quiet=False)\n",
    "# Newer NLTK also needs this metadata package\n",
    "try:\n",
    "    nltk.download(\"punkt_tab\", download_dir=NLTK_USER_DIR, force=True, quiet=False)\n",
    "except Exception:\n",
    "    pass  # older NLTK won't have it\n",
    "\n",
    "# 3) Verify both the PACKAGE and the Portuguese model are visible\n",
    "print(\"NLTK paths:\", nltk.data.path)\n",
    "print(\"Has package dir? \", pathlib.Path(NLTK_USER_DIR, \"tokenizers\", \"punkt\").exists())\n",
    "nltk.data.find(\"tokenizers/punkt\")                       # should NOT raise\n",
    "nltk.data.find(\"tokenizers/punkt/portuguese.pickle\")     # should NOT raise\n",
    "\n",
    "# Quick smoke test\n",
    "from nltk import word_tokenize\n",
    "print(word_tokenize(\"Olá mundo! Isto é um teste.\", language=\"portuguese\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f7f1e",
   "metadata": {},
   "source": [
    "**//PUT ALL PROCESSED DOMAINS AND SPLITS INTO PTBRVARID TABLE AND THEN TO TRAIN AND TEST DATA TABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f958b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESET] ptbrvarid recreated\n",
      "\n",
      "[DOMAIN] journalistic – 1 splits\n",
      "  [CLEAN] journalistic/train ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa03063b29bd48de88e418cb473f9f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/1842804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3398b4ac4bfe48839b1b44a67949d705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/1842804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e2ac19bf2e40b1a03bc493c63c867d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/1842804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e766d831cc848afa27041f1b8729982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/1842804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17716c8bfe645cdba9b77d6f3958f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1842804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c22783820f409c825d38dc5defe97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=1):   0%|          | 0/1717127 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d842c501736e4414af5ba6d17ddc08bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/1607201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c030ee465754c76bf121736cb39332a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1607201 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] journalistic/train: wrote 1,574,068\n",
      "\n",
      "[DOMAIN] legal – 1 splits\n",
      "  [CLEAN] legal/train ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6180ff8e05e4adaabb15cec0eb9dc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/4302002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52be751ce96e4c28a1ea7923ecbc0e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/4302002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6d24d22bae47d79161aa9f5f80a328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/4302002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2cf483406c42cfbf997fef2d4d7cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/4302002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bc936983d24304858e08a2e478fa00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4302002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d314d408c0f46da922d5c8500c25e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=1):   0%|          | 0/2099144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3919b4507164b71bd0d325763af7c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/1189672 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927e8e5fa3ab4b81bba000a4c1fadbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1189672 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] legal/train: wrote 1,118,443\n",
      "\n",
      "[DOMAIN] literature – 1 splits\n",
      "  [CLEAN] literature/train ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232d97a9b84248fb9aa2d57933ce8263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/81984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f91977594e496fa935ffe17ebfb0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/81984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec647b70f234276bb0fb7a9f977fd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/81984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab4e69785dc4f6e81880eb9e3aef61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/81984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fd22dc415c44e7841492b1e5eb7bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/81984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d4b4f9a02f4bbca1e10651d4695c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=1):   0%|          | 0/59514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7ed69a20d04fa0b53c3748c63dcf9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/40775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0636861e80a14eed9dd3cb250087435b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/40775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] literature/train: wrote 39,382\n",
      "\n",
      "[DOMAIN] politics – 1 splits\n",
      "  [CLEAN] politics/train ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8360318d48de4e2ba8155448b9064d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/34604 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372756a9c7044ea3afcbb9d9e71b4d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/34604 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4184040f9b74631be3ab556e6ba5c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/34604 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec2873ad1ad45909bb4c97d6c203880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/34604 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de4cbce13a044b2818aeafd44aa460d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/34604 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fafc63718cd3424d86a759f8fb1253eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=1):   0%|          | 0/32428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa045897647d46d890d9aaffaaa04bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/24425 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211209642e5b495dae3fb86f14a84feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/24425 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] politics/train: wrote 22,831\n",
      "\n",
      "[DOMAIN] social_media – 1 splits\n",
      "  [CLEAN] social_media/train ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed2d705df634080866dfa6b4ae0fc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/2678579 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e2de8aaa42400799b82ad89a59677d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/2678579 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae97e60c46804446acacb9bb9e455bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/2678579 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8aa52106c5433db7621a6fa81fc01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/2678579 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e7c95d9cb84306908688c2046bd1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2678579 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930ed6bcadd84bed92983ed3ab2cd3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=1):   0%|          | 0/262630 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0150868ae8d4d788a219d15ca022a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/220895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4459d9f859d4ff992c0fafb0e3b57e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/220895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] social_media/train: wrote 219,290\n",
      "\n",
      "[DOMAIN] web – 1 splits\n",
      "  [CLEAN] web/train ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85711336e16479aa3d55dbbe6569fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/133664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641e188a365b4c5f96b5cb8883d4cfc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/133664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8633cf26a5674478be2c521132cef444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/133664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450cfa6df6e34bf7ab6ee2a06c09859e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/133664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24811f0221df4b20a0e8c31cabddc9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/133664 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f30601458ff4bc992deb8864cb21ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=1):   0%|          | 0/101368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f3db27e25948749c8d2328b8735b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=1):   0%|          | 0/18949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6047fc757077405dabebdead52957306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/18949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [OK] web/train: wrote 17,714\n",
      "\n",
      "[ALL DONE] Inserted 2,991,728 rows total. Table now has 2,991,728 rows.\n",
      "✓ Domain integrity OK.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# OPTION A (canonical): use clean_one_domain_split() + strong jusText\n",
    "# Then write ALL processed domains/splits into DuckDB ptbrvarid\n",
    "# ============================================================\n",
    "\n",
    "from datasets import get_dataset_config_names, get_dataset_split_names\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = \"../data/duckdb/subs.duckdb\"\n",
    "BATCH_DB = 5000\n",
    "\n",
    "# ----------------------------\n",
    "# 0) SAFETY: enforce strong jusText is actually pruning\n",
    "#    (only needed if web_justext isn't already defined above)\n",
    "# ----------------------------\n",
    "try:\n",
    "    web_justext\n",
    "except NameError:\n",
    "    def web_justext(text: str,\n",
    "                    *,\n",
    "                    drop_if_no_good: bool = True,\n",
    "                    min_chars: int = 30,\n",
    "                    min_ratio: float = 0.20) -> str:\n",
    "        if not text:\n",
    "            return \"\"\n",
    "        try:\n",
    "            import justext\n",
    "            paras = justext.justext(text, justext.get_stoplist(\"Portuguese\"))\n",
    "            good  = [p.text for p in paras if p.class_type == \"good\"]\n",
    "            if not good:\n",
    "                return \"\" if drop_if_no_good else text\n",
    "            jt = \"\\n\".join(good).strip()\n",
    "            if len(jt) < min_chars:\n",
    "                return \"\"\n",
    "            if len(jt) / max(1, len(text)) < min_ratio:\n",
    "                return \"\"\n",
    "            return jt\n",
    "        except Exception:\n",
    "            return text\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Helpers (label mapping + schema reset)\n",
    "# ----------------------------\n",
    "def _label_to_name(ds, val):\n",
    "    \"\"\"Map int/str label to a readable name using HF features when available.\"\"\"\n",
    "    if isinstance(val, str):\n",
    "        return val\n",
    "    try:\n",
    "        names = ds.features[\"label\"].names\n",
    "        if isinstance(val, int) and 0 <= val < len(names):\n",
    "            return names[val]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return str(val)\n",
    "\n",
    "def _is_pt_br(lbl_name: str, raw_label) -> bool:\n",
    "    \"\"\"\n",
    "    Decide BR vs PT by normalized name; fallback to your rule:\n",
    "    label 0 == pt-PT (European) → everything else BR.\n",
    "    \"\"\"\n",
    "    s = (lbl_name or \"\").strip().lower().replace(\"_\", \"-\")\n",
    "    if s in {\"pt-br\", \"br\", \"ptbr\", \"brazil\", \"brazilian\"}:\n",
    "        return True\n",
    "    if s in {\"pt-pt\", \"pt\", \"eu\", \"european\"}:\n",
    "        return False\n",
    "    return (isinstance(raw_label, int) and raw_label != 0)\n",
    "\n",
    "def reset_ptbrvarid_table(con: duckdb.DuckDBPyConnection):\n",
    "    \"\"\"\n",
    "    Drop+recreate to avoid schema drift / column-order bugs forever.\n",
    "    \"\"\"\n",
    "    con.execute(\"DROP TABLE IF EXISTS ptbrvarid;\")\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE ptbrvarid (\n",
    "            dataset     TEXT,\n",
    "            domain      TEXT,\n",
    "            split       TEXT,\n",
    "            label       TEXT,\n",
    "            text_pt_br  TEXT,\n",
    "            text_pt_pt  TEXT\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) IMPORTANT: ensure clean_one_domain_split really drops jusText blanks\n",
    "#    If you already added a filter after jusText in the function, you can skip this.\n",
    "#    Otherwise, we defensively drop empties here too.\n",
    "# ----------------------------\n",
    "def _safe_text(s):\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Main run: process all domains/splits and insert\n",
    "# ----------------------------\n",
    "domains = get_dataset_config_names(\"liaad/PtBrVId-Raw\")\n",
    "\n",
    "with duckdb.connect(DB_PATH) as con:\n",
    "    reset_ptbrvarid_table(con)\n",
    "    print(\"[RESET] ptbrvarid recreated\")\n",
    "\n",
    "    grand_total = 0\n",
    "\n",
    "    for domain in domains:\n",
    "        splits = get_dataset_split_names(\"liaad/PtBrVId-Raw\", domain)\n",
    "        print(f\"\\n[DOMAIN] {domain} – {len(splits)} splits\")\n",
    "\n",
    "        for split in splits:\n",
    "            print(f\"  [CLEAN] {domain}/{split} ...\")\n",
    "\n",
    "            # Force jusText on ALL domains\n",
    "            ds = clean_one_domain_split(\n",
    "                domain, split,\n",
    "                keep_accents=True,\n",
    "                use_author_transforms=True,\n",
    "                apply_author_filters=True,\n",
    "                num_proc=1,\n",
    "                batch_size=1000,\n",
    "                justext_scope=\"all\",\n",
    "            )\n",
    "\n",
    "            buf = []\n",
    "            wrote = 0\n",
    "\n",
    "            for ex in ds.to_iterable_dataset():\n",
    "                text = _safe_text(ex.get(\"text\", \"\"))\n",
    "                if not text:\n",
    "                    continue  # drop blanks (including jusText-pruned rows)\n",
    "\n",
    "                lbl_name = _label_to_name(ds, ex.get(\"label\"))\n",
    "                is_br = _is_pt_br(lbl_name, ex.get(\"label\"))\n",
    "\n",
    "                buf.append({\n",
    "                    \"dataset\": \"PtBrVId\",   # keep consistent with build_scripts.py\n",
    "                    \"domain\": domain,\n",
    "                    \"split\": split,\n",
    "                    \"label\": \"pt-BR\" if is_br else \"pt-PT\",\n",
    "                    \"text_pt_br\": text if is_br else None,\n",
    "                    \"text_pt_pt\": text if not is_br else None,\n",
    "                })\n",
    "\n",
    "                if len(buf) >= BATCH_DB:\n",
    "                    df = pd.DataFrame(buf)\n",
    "                    con.register(\"ptbr_buf\", df)\n",
    "                    con.execute(\"\"\"\n",
    "                        INSERT INTO ptbrvarid (dataset, domain, split, label, text_pt_br, text_pt_pt)\n",
    "                        SELECT dataset, domain, split, label, text_pt_br, text_pt_pt FROM ptbr_buf\n",
    "                    \"\"\")\n",
    "                    con.unregister(\"ptbr_buf\")\n",
    "                    wrote += len(buf)\n",
    "                    buf.clear()\n",
    "\n",
    "            if buf:\n",
    "                df = pd.DataFrame(buf)\n",
    "                con.register(\"ptbr_buf\", df)\n",
    "                con.execute(\"\"\"\n",
    "                    INSERT INTO ptbrvarid (dataset, domain, split, label, text_pt_br, text_pt_pt)\n",
    "                    SELECT dataset, domain, split, label, text_pt_br, text_pt_pt FROM ptbr_buf\n",
    "                \"\"\")\n",
    "                con.unregister(\"ptbr_buf\")\n",
    "                wrote += len(buf)\n",
    "                buf.clear()\n",
    "\n",
    "            grand_total += wrote\n",
    "            print(f\"  [OK] {domain}/{split}: wrote {wrote:,}\")\n",
    "\n",
    "    final_count = con.execute(\"SELECT COUNT(*) FROM ptbrvarid\").fetchone()[0]\n",
    "    print(f\"\\n[ALL DONE] Inserted {grand_total:,} rows total. Table now has {final_count:,} rows.\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # 4) Hard integrity check: domain must be one of the known subset labels\n",
    "    # ----------------------------\n",
    "    KNOWN = (\"journalistic\",\"legal\",\"web\",\"literature\",\"politics\",\"social_media\")\n",
    "    bad = con.execute(f\"\"\"\n",
    "        SELECT COUNT(*) FROM ptbrvarid\n",
    "        WHERE dataset='PtBrVId'\n",
    "          AND (domain IS NULL OR lower(trim(domain)) NOT IN {KNOWN})\n",
    "    \"\"\").fetchone()[0]\n",
    "    assert bad == 0, f\"Found {bad} rows with invalid domain!\"\n",
    "\n",
    "print(\"✓ Domain integrity OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15177eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>domain</th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>text_pt_br</th>\n",
       "      <th>text_pt_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>None</td>\n",
       "      <td>Cardoso e Cunha \"Insatisfatório\" O resultado do referendo francês é insatisfatório, tímido e modesto. Os problemas da Comunidade Europeia exigiam, da parte de um país que sempre esteve na linha da frente, uma vitória mais clara. A vitória tangencial do \"sim\" dá que pensar. Esta margem tão pequena que deu a vitória ao \"sim\" torna imprevisível o que vai acontecer na Grã-Bretanha.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>None</td>\n",
       "      <td>Santo Tirso de fora Apesar da intenção das principais autarquias do Ave, para já Santo Tirso quer ficar de fora deste processo. Joaquim Couto, o presidente da edilidade tirsense, não está muito convencido da interesse das empresas e prefere concessionar alguns serviços a privados. É o caso da recolha e transporte dos lixos domésticos e da gestão e exploração do abastecimento de água. \"A concessão a privados dá mais transparência à gestão da autarquia\", referiu ao PÚBLICO o edil. Quanto às empresas públicas municipais, Couto duvida da sua utilidade e pergunta mesmo se valerá a pena autonomizar sem ter garantias de que não haverá um aumento das despesas e melhorias nos serviços. De resto, o autarca garante ainda que \"a gestão privada das coisas tem-se mostrado mais eficiente para os dinheiros públicos\". Em vez da legislação que permite a criação de empresas municipais, Couto preferia ter visto aprovada legislação que aumentasse o poder das câmaras e que lhes desse \"mais autonomia financeira\". \"Neste campo, somos os últimos da Europa\", refere, garantindo ainda que as verbas distribuídas pelo Estado às autarquias deveriam \"triplicar\". É que, diz, \"nenhuma empresa funciona se não tiver uma lei de financiamento capaz\". Emília Monteiro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>None</td>\n",
       "      <td>\"1 Rpm\" é a abreviatura para \"Uma Revolução por Minuto\", e a respectiva tradução inglesa, uma vez que os LX-90 de Rui Pregal da Cunha e Pedro Paulo Gonçalves (ex-Heróis do Mar) vão editar não um, mas dois álbuns de estreia. Lembra a estratégia dos seus colegas de editora Guns N' Roses, até porque o que permitirá diferenciar os dois discos nos escaparates serão os contrastes de o roxo numa das capas é amarelo na outra e vice-versa. Mas as comparações acabam aí: Ao contrário dos Roses, os discos dos LX-90 incluem as mesmas faixas, com a diferença de num disco elas surgirem cantadas em português e no outro em inglês. Como pode deduzir-se deste aparato, trata-se de um dos lançamentos mais ousados de sempre no capítulo da música feita no nosso país, e tem pelas próprias exigências que se vítima de uma série de acidentes de percurso. Embora o disco começasse por ser gravado nos estúdios Exit, com a produção dos ingleses Sam e Danny, estes consideraram que faltavam ali máquinas indispensáveis, e o grupo mudou-se para os estúdios de Paço de Arcos da Valentim de Carvalho. Em Setembro, com a mesma dupla de produtores, a banda voou para Londres, no intuito de ultimar as misturas finais, tendo-se então avançado o princípio deste mês como data de edição do trabalho.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>None</td>\n",
       "      <td>Luís António Mendes Nobre pode, em Outubro, por alturada 5ª edição do Festival Internacional de Música de Macau, concretizar, como confessou, \"um velho sonho\". Do Oriente, Mendes Nobre só conhece a Tailândia, onde fez férias há dois anos. Para o pianista Adriano Jordão, director artístico do certame, o concurso \"correu muito bem. À Missão de Macau chegaram 306 boletins, o que para o nível exigido nas perguntas pode considerar-se bastante bom\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>None</td>\n",
       "      <td>Não posso dizer mais nada. Por que é que me está a fazer perguntas sobre Lisboa? Porque foi presidente da Câmara durante dez anos e nota-se que foi uma fase muito marcante da sua vida, à qual ficou afectivamente muito ligado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>None</td>\n",
       "      <td>A vítima, de 32 anos, era conhecida no local como alcoólica: O relatório da PJ salienta que o casal vivia em \"condições miseráveis\". O juiz de instrução criminal confirmou a detenção do suspeito, enquanto aguarda julgamento.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>None</td>\n",
       "      <td>O desafio começou com ajustamentos mútuos, sendo patente a vantagem dos azuis de Belém, graças à supremacia revelada pelo seu sector intermediário. Mauro Airez assume um claro papel de liderança e pouco bastou para Rodolfo Reis ver que Nascimento não estava à altura da capacidade técnica e física do argentino. A oito minutos do intervalo substituiu--o por Dreiffus, encarregando Elias da missão que Nascimento não estava a desempenhar cabalmente. Mais soltos e com uma maior ligação entre todos os sectores da equipa, os visitantes dispuseram, aliás, da primeira ocasião de golo, quando Gonçalves desperdiçou o ensejo de bater Acácio, ontem sujeito a poucas mas complicadas intervenções, normalmente geradas ou finalizadas por Mauro Airez.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-BR</td>\n",
       "      <td>Suspeito que os maiores interessados em manter a semi-clandestinidade são, justamente, os delinquentes inclusive na polícia, beneficiados por propinas. A hipocrisia está no seguinte: Os governos surgem, hoje, como os maiores promotores da jogatina através de loterias, prometendo a redenção dos até agora, seu maior beneficiário foi, aliás, o deputado João Alves. Os governantes apostam na ilusão do pobre. Como se já não bastasse a gatunagem dos impostos, tiram seu dinheiro, prometendo obras sociais para esse mesmo pobre. É, na verdade, quase um estelionato: Todos que conhecem um mínimo de bastidores de administração sabem como são desperdiçados recursos sociais. Não é só.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>None</td>\n",
       "      <td>Eleições vão custar 180 mil contos O ministro da Administração Interna, Manuel Pereira, revelou ontem que os preparativos para as próximas eleições legislativas vão custar ao seu ministério cerca de 180 mil contos.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>PtBrVId</td>\n",
       "      <td>journalistic</td>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>None</td>\n",
       "      <td>É da competência do Ministério dos Negócios Estrangeiros manter actualizado o levantamento das comunidades portuguesas emigradas ou em actividades de cooperação em outros países. Trata-se de uma tarefa delegada na Secretaria de Estado das Comunidades e executada pelas embaixadas e consulados. Na dependência do Ministério dos Negócios Estrangeiros funciona permanentemente um órgão de trabalho chamado \"serviço de protecção consular\", ao qual cabe, por mera rotina, manter actualizados os dados gerais sobre as comunidades portuguesas. Deve ser um registo que possibilite determinar rapidamente o número de cidadãos e sua localização, permitindo saber-se também se são indivíduos singulares ou famílias e se no conjunto há crianças. No planeamento básico, por regra, cabe aos adidos militares inventariar aeroportos (ou portos) de escala e viabilidade de reabastecimento de aeronaves ou navios e à diplomacia assegurar a cooperação dos países vizinhos do \"alvo\" a alcançar para a operação de protecção ou repatriamento. Foi o que se passou com a situação no Zaire, em que a diplomacia portuguesa assegurou a cooperação do Governo do Congo-Brazzaville, nas duas situações em que o \"plano de regresso\" foi activado.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset        domain  split  label  \\\n",
       "0      PtBrVId  journalistic  train  pt-PT   \n",
       "1      PtBrVId  journalistic  train  pt-PT   \n",
       "2      PtBrVId  journalistic  train  pt-PT   \n",
       "3      PtBrVId  journalistic  train  pt-PT   \n",
       "4      PtBrVId  journalistic  train  pt-PT   \n",
       "...        ...           ...    ...    ...   \n",
       "49995  PtBrVId  journalistic  train  pt-PT   \n",
       "49996  PtBrVId  journalistic  train  pt-PT   \n",
       "49997  PtBrVId  journalistic  train  pt-BR   \n",
       "49998  PtBrVId  journalistic  train  pt-PT   \n",
       "49999  PtBrVId  journalistic  train  pt-PT   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text_pt_br  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        None   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        None   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        None   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        None   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        None   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...   \n",
       "49995                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    None   \n",
       "49996                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    None   \n",
       "49997  Suspeito que os maiores interessados em manter a semi-clandestinidade são, justamente, os delinquentes inclusive na polícia, beneficiados por propinas. A hipocrisia está no seguinte: Os governos surgem, hoje, como os maiores promotores da jogatina através de loterias, prometendo a redenção dos até agora, seu maior beneficiário foi, aliás, o deputado João Alves. Os governantes apostam na ilusão do pobre. Como se já não bastasse a gatunagem dos impostos, tiram seu dinheiro, prometendo obras sociais para esse mesmo pobre. É, na verdade, quase um estelionato: Todos que conhecem um mínimo de bastidores de administração sabem como são desperdiçados recursos sociais. Não é só.   \n",
       "49998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    None   \n",
       "49999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text_pt_pt  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Cardoso e Cunha \"Insatisfatório\" O resultado do referendo francês é insatisfatório, tímido e modesto. Os problemas da Comunidade Europeia exigiam, da parte de um país que sempre esteve na linha da frente, uma vitória mais clara. A vitória tangencial do \"sim\" dá que pensar. Esta margem tão pequena que deu a vitória ao \"sim\" torna imprevisível o que vai acontecer na Grã-Bretanha.  \n",
       "1                               Santo Tirso de fora Apesar da intenção das principais autarquias do Ave, para já Santo Tirso quer ficar de fora deste processo. Joaquim Couto, o presidente da edilidade tirsense, não está muito convencido da interesse das empresas e prefere concessionar alguns serviços a privados. É o caso da recolha e transporte dos lixos domésticos e da gestão e exploração do abastecimento de água. \"A concessão a privados dá mais transparência à gestão da autarquia\", referiu ao PÚBLICO o edil. Quanto às empresas públicas municipais, Couto duvida da sua utilidade e pergunta mesmo se valerá a pena autonomizar sem ter garantias de que não haverá um aumento das despesas e melhorias nos serviços. De resto, o autarca garante ainda que \"a gestão privada das coisas tem-se mostrado mais eficiente para os dinheiros públicos\". Em vez da legislação que permite a criação de empresas municipais, Couto preferia ter visto aprovada legislação que aumentasse o poder das câmaras e que lhes desse \"mais autonomia financeira\". \"Neste campo, somos os últimos da Europa\", refere, garantindo ainda que as verbas distribuídas pelo Estado às autarquias deveriam \"triplicar\". É que, diz, \"nenhuma empresa funciona se não tiver uma lei de financiamento capaz\". Emília Monteiro  \n",
       "2      \"1 Rpm\" é a abreviatura para \"Uma Revolução por Minuto\", e a respectiva tradução inglesa, uma vez que os LX-90 de Rui Pregal da Cunha e Pedro Paulo Gonçalves (ex-Heróis do Mar) vão editar não um, mas dois álbuns de estreia. Lembra a estratégia dos seus colegas de editora Guns N' Roses, até porque o que permitirá diferenciar os dois discos nos escaparates serão os contrastes de o roxo numa das capas é amarelo na outra e vice-versa. Mas as comparações acabam aí: Ao contrário dos Roses, os discos dos LX-90 incluem as mesmas faixas, com a diferença de num disco elas surgirem cantadas em português e no outro em inglês. Como pode deduzir-se deste aparato, trata-se de um dos lançamentos mais ousados de sempre no capítulo da música feita no nosso país, e tem pelas próprias exigências que se vítima de uma série de acidentes de percurso. Embora o disco começasse por ser gravado nos estúdios Exit, com a produção dos ingleses Sam e Danny, estes consideraram que faltavam ali máquinas indispensáveis, e o grupo mudou-se para os estúdios de Paço de Arcos da Valentim de Carvalho. Em Setembro, com a mesma dupla de produtores, a banda voou para Londres, no intuito de ultimar as misturas finais, tendo-se então avançado o princípio deste mês como data de edição do trabalho.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Luís António Mendes Nobre pode, em Outubro, por alturada 5ª edição do Festival Internacional de Música de Macau, concretizar, como confessou, \"um velho sonho\". Do Oriente, Mendes Nobre só conhece a Tailândia, onde fez férias há dois anos. Para o pianista Adriano Jordão, director artístico do certame, o concurso \"correu muito bem. À Missão de Macau chegaram 306 boletins, o que para o nível exigido nas perguntas pode considerar-se bastante bom\".  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Não posso dizer mais nada. Por que é que me está a fazer perguntas sobre Lisboa? Porque foi presidente da Câmara durante dez anos e nota-se que foi uma fase muito marcante da sua vida, à qual ficou afectivamente muito ligado.  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...  \n",
       "49995                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           A vítima, de 32 anos, era conhecida no local como alcoólica: O relatório da PJ salienta que o casal vivia em \"condições miseráveis\". O juiz de instrução criminal confirmou a detenção do suspeito, enquanto aguarda julgamento.  \n",
       "49996                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      O desafio começou com ajustamentos mútuos, sendo patente a vantagem dos azuis de Belém, graças à supremacia revelada pelo seu sector intermediário. Mauro Airez assume um claro papel de liderança e pouco bastou para Rodolfo Reis ver que Nascimento não estava à altura da capacidade técnica e física do argentino. A oito minutos do intervalo substituiu--o por Dreiffus, encarregando Elias da missão que Nascimento não estava a desempenhar cabalmente. Mais soltos e com uma maior ligação entre todos os sectores da equipa, os visitantes dispuseram, aliás, da primeira ocasião de golo, quando Gonçalves desperdiçou o ensejo de bater Acácio, ontem sujeito a poucas mas complicadas intervenções, normalmente geradas ou finalizadas por Mauro Airez.  \n",
       "49997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       None  \n",
       "49998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Eleições vão custar 180 mil contos O ministro da Administração Interna, Manuel Pereira, revelou ontem que os preparativos para as próximas eleições legislativas vão custar ao seu ministério cerca de 180 mil contos.  \n",
       "49999                                                             É da competência do Ministério dos Negócios Estrangeiros manter actualizado o levantamento das comunidades portuguesas emigradas ou em actividades de cooperação em outros países. Trata-se de uma tarefa delegada na Secretaria de Estado das Comunidades e executada pelas embaixadas e consulados. Na dependência do Ministério dos Negócios Estrangeiros funciona permanentemente um órgão de trabalho chamado \"serviço de protecção consular\", ao qual cabe, por mera rotina, manter actualizados os dados gerais sobre as comunidades portuguesas. Deve ser um registo que possibilite determinar rapidamente o número de cidadãos e sua localização, permitindo saber-se também se são indivíduos singulares ou famílias e se no conjunto há crianças. No planeamento básico, por regra, cabe aos adidos militares inventariar aeroportos (ou portos) de escala e viabilidade de reabastecimento de aeronaves ou navios e à diplomacia assegurar a cooperação dos países vizinhos do \"alvo\" a alcançar para a operação de protecção ou repatriamento. Foi o que se passou com a situação no Zaire, em que a diplomacia portuguesa assegurou a cooperação do Governo do Congo-Brazzaville, nas duas situações em que o \"plano de regresso\" foi activado.  \n",
       "\n",
       "[50000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = duckdb.connect('../data/duckdb/subs.duckdb')\n",
    "con.execute('SELECT * FROM ptbrvarid WHERE dataset=\\'PtBrVId\\' LIMIT 50000').df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f92b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x783b47bb44b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb, pathlib, pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 140)\n",
    "\n",
    "con = duckdb.connect(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "# Known domain names to distinguish real domain vs misplaced text\n",
    "KNOWN_DOMAINS = (\"journalistic\",\"legal\",\"web\",\"literature\",\"politics\",\"social_media\")\n",
    "\n",
    "con.execute(\"DROP VIEW IF EXISTS ptbrvid_repaired_v;\")\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW ptbrvid_repaired_v AS\n",
    "WITH raw AS (\n",
    "  SELECT dataset, domain, split, label, text_pt_br, text_pt_pt\n",
    "  FROM ptbrvarid\n",
    "  WHERE dataset='PtBrVId'\n",
    "),\n",
    "norm AS (\n",
    "  SELECT\n",
    "    -- language: prefer explicit label if present, else take the literal that was stuffed into text_pt_br\n",
    "    CASE\n",
    "      WHEN lower(label) IN ('pt-br','pt-pt') THEN CASE WHEN lower(label)='pt-br' THEN 'pt-BR' ELSE 'pt-PT' END\n",
    "      WHEN text_pt_br IN ('pt-BR','pt-PT')      THEN text_pt_br\n",
    "      ELSE NULL\n",
    "    END AS lang,\n",
    "\n",
    "    -- text: prefer the proper text columns; if empty, fall back to `domain` only if it looks like text\n",
    "    CASE\n",
    "      WHEN text_pt_br IS NOT NULL AND text_pt_br NOT IN ('pt-BR','pt-PT') THEN text_pt_br\n",
    "      WHEN text_pt_pt IS NOT NULL AND text_pt_pt NOT IN ('pt-BR','pt-PT') THEN text_pt_pt\n",
    "      WHEN domain IS NOT NULL AND lower(domain) NOT IN {KNOWN_DOMAINS}\n",
    "           AND length(domain) > 40 THEN domain\n",
    "      ELSE NULL\n",
    "    END AS text,\n",
    "\n",
    "    split, domain\n",
    "  FROM raw\n",
    "),\n",
    "ok AS (\n",
    "  SELECT\n",
    "    'PtBrVId' AS dataset,\n",
    "    split,\n",
    "    lang  AS label,\n",
    "    CASE WHEN lang='pt-BR' THEN text END AS text_pt_br,\n",
    "    CASE WHEN lang='pt-PT' THEN text END AS text_pt_pt\n",
    "  FROM norm\n",
    "  WHERE lang IS NOT NULL AND text IS NOT NULL\n",
    ")\n",
    "SELECT * FROM ok;\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
