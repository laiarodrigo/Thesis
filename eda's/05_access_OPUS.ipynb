{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105e4dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brazilian file : OpenSubtitles.pt-pt_BR.pt_BR\n",
      "European file  : OpenSubtitles.pt-pt_BR.pt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import duckdb, itertools, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path;  import duckdb, itertools, tqdm, mmap, math\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------------------------------\n",
    "CACHE_DIR = Path(\"../data/opus_cache\")\n",
    "DB_PATH    = Path(\"../data/duckdb/subs.duckdb\")\n",
    "BATCH_SIZE = 50_000           # tune to your RAM/SSD speed\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "def find_files():\n",
    "    br = None\n",
    "    pt = None\n",
    "    for f in CACHE_DIR.iterdir():\n",
    "        fn = f.name\n",
    "        if fn.endswith(\".pt_BR\"):      # ← brazilian sentences\n",
    "            br = f\n",
    "        elif fn.endswith(\".pt\") and not fn.endswith(\".pt_BR\"):\n",
    "            # ends with '.pt' but NOT '.pt_BR' → european sentences\n",
    "            pt = f\n",
    "    if br is None or pt is None:\n",
    "        raise RuntimeError(\n",
    "            \"Could not uniquely identify the two files.\\n\"\n",
    "            \"Expected one file whose name ends with '.pt_BR' (br side) and\\n\"\n",
    "            \"one that ends with plain '.pt' (pt-PT side). Check CACHE_DIR!\"\n",
    "        )\n",
    "    return br, pt\n",
    "\n",
    "\n",
    "BR_PATH, PT_PATH = find_files()\n",
    "print(\"Brazilian file :\", BR_PATH.name)\n",
    "print(\"European file  :\", PT_PATH.name)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) DuckDB schema  (sequence + table   → works in every DuckDB version)\n",
    "# -------------------------------------------------------------------------\n",
    "DDL = \"\"\"\n",
    "CREATE SEQUENCE IF NOT EXISTS seq_opus_moses START 1;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS opus_moses (\n",
    "    pair_id     BIGINT DEFAULT nextval('seq_opus_moses') PRIMARY KEY,\n",
    "    sent_pt_br  TEXT,\n",
    "    sent_pt_pt  TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "def get_connection():\n",
    "    DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    con = duckdb.connect(str(DB_PATH))\n",
    "    con.execute(DDL)\n",
    "    return con\n",
    "\n",
    "def insert_batch(con, rows):\n",
    "    con.executemany(\n",
    "        \"INSERT INTO opus_moses (sent_pt_br, sent_pt_pt) VALUES (?, ?)\",\n",
    "        rows\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2) stream the two files line-by-line and insert\n",
    "# -------------------------------------------------------------------------\n",
    "def sentence_pairs():\n",
    "    with BR_PATH.open('r', encoding='utf-8') as br_f, \\\n",
    "         PT_PATH.open('r', encoding='utf-8') as pt_f:\n",
    "        for br_line, pt_line in zip(br_f, pt_f):\n",
    "            yield br_line.rstrip(\"\\n\"), pt_line.rstrip(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc21d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def show_context(df: pd.DataFrame,\n",
    "                 id_value,\n",
    "                 id_col: str = \"pair_id\",\n",
    "                 n: int = 2) -> None:\n",
    "    \"\"\"\n",
    "    Print *n* rows before and after the row whose `id_col` equals `id_value`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to search.\n",
    "    id_value : Any\n",
    "        The value to match in `id_col`.\n",
    "    id_col : str, default \"pair_id\"\n",
    "        Which column contains the identifier.\n",
    "    n : int, default 2\n",
    "        How many rows of context to show on each side.\n",
    "    \"\"\"\n",
    "    # find the positional index of the first matching row\n",
    "    matches = df.index[df[id_col] == id_value]\n",
    "    if matches.empty:\n",
    "        raise ValueError(f\"{id_value!r} not found in column {id_col!r}\")\n",
    "\n",
    "    i = matches[0]                       # position of the match\n",
    "    start = max(0, i - n)                # clamp to frame boundaries\n",
    "    end   = min(len(df), i + n + 1)\n",
    "\n",
    "    print(df.iloc[start:end].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import duckdb, pathlib, time\n",
    "\n",
    "# BAK = pathlib.Path(\"../data/duckdb/subs.duckdb.bak\").resolve()\n",
    "\n",
    "# con = duckdb.connect()                       # open an in-memory connection\n",
    "# con.execute(\"SET enable_progress_bar=true\")  # show progress for slow steps\n",
    "\n",
    "# # 1. attach the backup => DuckDB replays the 4 GB WAL (be patient: minutes)\n",
    "# t0 = time.time()\n",
    "# con.execute(f\"ATTACH '{BAK}' AS bak\")\n",
    "# print(\"WAL replay finished in\", round(time.time()-t0, 1), \"s\")\n",
    "\n",
    "# # 2. drop table, index & sequence that belong to opus_moses\n",
    "# con.execute(\"DROP TABLE IF EXISTS bak.opus_moses\")\n",
    "# con.execute(\"DROP SEQUENCE IF EXISTS bak.seq_opus_moses\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b562c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. checkpoint so the 4 GB WAL is folded into the main file  (now 0 B)\n",
    "# con.execute(\"PRAGMA force_checkpoint;\")\n",
    "# con.execute(\"CHECKPOINT;\")\n",
    "\n",
    "# # 4. vacuum to reclaim the table’s disk space\n",
    "# con.execute(\"VACUUM\")                        # rewrites the file compactly\n",
    "\n",
    "# # 5. detach and close\n",
    "# con.execute(\"DETACH bak\")\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import os, duckdb, time             # ‹-- getsize is in os.path\n",
    "\n",
    "# DB_PATH = Path(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "# print(\"DB:\", DB_PATH, \"size =\", os.path.getsize(DB_PATH)/1e6, \"MB\")\n",
    "# wal = DB_PATH.with_suffix(\".duckdb.wal\")\n",
    "# if wal.exists():\n",
    "#     print(\"WAL:\", wal, \"size =\", os.path.getsize(wal)/1e6, \"MB\")\n",
    "\n",
    "# t0 = time.time()\n",
    "# print(\"Connecting…\", flush=True)\n",
    "# con = duckdb.connect(DB_PATH)\n",
    "# print(\"Connected in\", round(time.time()-t0,2), \"s\")\n",
    "\n",
    "# con.execute(\"PRAGMA database_size;\").show()   # quick sanity check\n",
    "# con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con = duckdb.connect(\"../data/duckdb/subs.duckdb\")\n",
    "# con.execute(\"PRAGMA force_checkpoint;\")\n",
    "# con.execute(\"CHECKPOINT;\")\n",
    "# con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a8cc8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# paths to the two files you copied by hand\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m CACHE_DIR = \u001b[43mPath\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m../data/opus_cache\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m BR_PATH   = CACHE_DIR / \u001b[33m\"\u001b[39m\u001b[33mOpenSubtitles.pt-pt_BR.pt_BR\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m PT_PATH   = CACHE_DIR / \u001b[33m\"\u001b[39m\u001b[33mOpenSubtitles.pt-pt_BR.pt\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# paths to the two files you copied by hand\n",
    "# -------------------------------------------------------------------------\n",
    "CACHE_DIR = Path(\"../data/opus_cache\")\n",
    "BR_PATH   = CACHE_DIR / \"OpenSubtitles.pt-pt_BR.pt_BR\"\n",
    "PT_PATH   = CACHE_DIR / \"OpenSubtitles.pt-pt_BR.pt\"\n",
    "\n",
    "DB_PATH   = Path(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "BATCH_SIZE = 50_000        # change freely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# helper – fast line-count (used only for nice tqdm total)\n",
    "# -------------------------------------------------------------------------\n",
    "def count_lines(fp: Path) -> int:\n",
    "    with fp.open('rb') as f, mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "        return mm.read().count(b'\\n')\n",
    "    \n",
    "print(\"Counting lines in\", BR_PATH.name)\n",
    "\n",
    "TOTAL_LINES = count_lines(BR_PATH)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# schema: de-dupe + unique guard + checkpoint\n",
    "# -------------------------------------------------------------------------\n",
    "DDL = \"\"\"\n",
    "CREATE SEQUENCE IF NOT EXISTS seq_opus_moses START 1;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS opus_moses (\n",
    "     line_no     BIGINT PRIMARY KEY,                 -- 1-based position\n",
    "     pair_id     BIGINT DEFAULT nextval('seq_opus_moses'),\n",
    "     sent_pt_br  TEXT,\n",
    "     sent_pt_pt  TEXT\n",
    ");\n",
    "\n",
    "-- 1) remove earlier duplicates, keep the lowest line_no\n",
    "DELETE FROM opus_moses\n",
    "USING (\n",
    "    SELECT line_no,\n",
    "           ROW_NUMBER() OVER (\n",
    "               PARTITION BY sent_pt_br, sent_pt_pt\n",
    "               ORDER BY line_no\n",
    "           ) AS dup\n",
    "    FROM opus_moses\n",
    ") AS tmp\n",
    "WHERE opus_moses.line_no = tmp.line_no\n",
    "  AND tmp.dup > 1;\n",
    "\n",
    "-- 2) future inserts may *try* to add a duplicate: stop them silently\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS uq_text_pair\n",
    "    ON opus_moses(sent_pt_br, sent_pt_pt);\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# open DB + run the DDL\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"Connecting to DuckDB database:\", DB_PATH)\n",
    "con = duckdb.connect(DB_PATH)\n",
    "con.execute(\"SET checkpoint_threshold='100MB'\")\n",
    "con.execute(\"SET enable_progress_bar=true\")\n",
    "print(\"Creating schema if not exists...\")\n",
    "con.execute(DDL)\n",
    "print(\"Schema created or already exists.\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# find how many lines are already in the table  (= checkpoint)\n",
    "# -------------------------------------------------------------------------\n",
    "done = con.execute(\"SELECT MAX(line_no) FROM opus_moses\").fetchone()[0] or 0\n",
    "print(f\"⏩ resuming after line {done:,}\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# iterate over the *remaining* lines only\n",
    "# -------------------------------------------------------------------------\n",
    "def sentence_pairs(start_at: int):\n",
    "    with BR_PATH.open('r', encoding='utf-8') as br_f, \\\n",
    "         PT_PATH.open('r', encoding='utf-8') as pt_f:\n",
    "        # skip the already-imported prefix efficiently\n",
    "        for _ in range(start_at):\n",
    "            next(br_f); next(pt_f)\n",
    "\n",
    "        for ln, (br, pt) in enumerate(zip(br_f, pt_f), start_at + 1):\n",
    "            yield ln, br.rstrip(\"\\n\"), pt.rstrip(\"\\n\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# main load loop\n",
    "# -------------------------------------------------------------------------\n",
    "batch = []\n",
    "for ln, src, tgt in tqdm.tqdm(\n",
    "        sentence_pairs(done),\n",
    "        total=TOTAL_LINES - done,\n",
    "        desc=\"Importing\", unit=\"pairs\"):\n",
    "\n",
    "    batch.append((ln, src, tgt))\n",
    "\n",
    "    if len(batch) >= BATCH_SIZE:\n",
    "        con.executemany(\n",
    "            \"INSERT OR IGNORE INTO opus_moses (line_no, sent_pt_br, sent_pt_pt) \"\n",
    "            \"VALUES (?, ?, ?)\",\n",
    "            batch)\n",
    "        batch.clear()\n",
    "\n",
    "# tail\n",
    "if batch:\n",
    "    con.executemany(\n",
    "        \"INSERT OR IGNORE INTO opus_moses (line_no, sent_pt_br, sent_pt_pt) \"\n",
    "        \"VALUES (?, ?, ?)\",\n",
    "        batch)\n",
    "    \n",
    "con.execute(\"PRAGMA force_checkpoint;\")   # folds WAL pages into the DB\n",
    "con.execute(\"CHECKPOINT;\") \n",
    "\n",
    "con.close()\n",
    "print(\"✔ import complete; duplicates prevented going forward.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7044532",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(DB_PATH, read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215911de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM opus_moses\n",
    "    LIMIT 500000\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c480dfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_no</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>sent_pt_br</th>\n",
       "      <th>sent_pt_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>o diretor mueller acaba de nomear nos um númer...</td>\n",
       "      <td>Em episódios anteriores... O diretor Mueller a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>bruce ivins é o nosso melhor homem com antraz,...</td>\n",
       "      <td>- Bruce Ivins é o perito em antraz. - Então qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>eu conheço a maioria dos americanos não estão ...</td>\n",
       "      <td>Temos de entrar através do complexo de herói d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>bruce,vocêé considerando fazer fisicamente mal...</td>\n",
       "      <td>E, em vez disso, incomodam patriotas trabalhad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>você fez isso, dr, ivins?</td>\n",
       "      <td>Fez isto, Dr. Ivins?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13262983</th>\n",
       "      <td>16031946</td>\n",
       "      <td>16031947</td>\n",
       "      <td>Talvez um pouco cansada, é tudo.</td>\n",
       "      <td>Talvez um pouco cansada.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13262984</th>\n",
       "      <td>16031947</td>\n",
       "      <td>16031948</td>\n",
       "      <td>Não está comendo sua torta de espaguete.</td>\n",
       "      <td>Não estás a comer a tua tarte de esparguete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13262985</th>\n",
       "      <td>16031949</td>\n",
       "      <td>16031950</td>\n",
       "      <td>Estava pensando, quero te pedir dinheiro empre...</td>\n",
       "      <td>Acho que preciso que me emprestes algum dinheiro.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13262986</th>\n",
       "      <td>16031950</td>\n",
       "      <td>16031951</td>\n",
       "      <td>E a minha resposta pra isso, claro, é não.</td>\n",
       "      <td>E a minha resposta, claro, é \"não\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13262987</th>\n",
       "      <td>16031951</td>\n",
       "      <td>16031952</td>\n",
       "      <td>Haverá um grande concurso tortas em Jonesville...</td>\n",
       "      <td>Há um grande concurso de tartes em Jonesville ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13262988 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           line_no   pair_id  \\\n",
       "0                1         1   \n",
       "1                2         2   \n",
       "2                3         3   \n",
       "3                4         4   \n",
       "4                5         5   \n",
       "...            ...       ...   \n",
       "13262983  16031946  16031947   \n",
       "13262984  16031947  16031948   \n",
       "13262985  16031949  16031950   \n",
       "13262986  16031950  16031951   \n",
       "13262987  16031951  16031952   \n",
       "\n",
       "                                                 sent_pt_br  \\\n",
       "0         o diretor mueller acaba de nomear nos um númer...   \n",
       "1         bruce ivins é o nosso melhor homem com antraz,...   \n",
       "2         eu conheço a maioria dos americanos não estão ...   \n",
       "3         bruce,vocêé considerando fazer fisicamente mal...   \n",
       "4                                 você fez isso, dr, ivins?   \n",
       "...                                                     ...   \n",
       "13262983                   Talvez um pouco cansada, é tudo.   \n",
       "13262984           Não está comendo sua torta de espaguete.   \n",
       "13262985  Estava pensando, quero te pedir dinheiro empre...   \n",
       "13262986         E a minha resposta pra isso, claro, é não.   \n",
       "13262987  Haverá um grande concurso tortas em Jonesville...   \n",
       "\n",
       "                                                 sent_pt_pt  \n",
       "0         Em episódios anteriores... O diretor Mueller a...  \n",
       "1         - Bruce Ivins é o perito em antraz. - Então qu...  \n",
       "2         Temos de entrar através do complexo de herói d...  \n",
       "3         E, em vez disso, incomodam patriotas trabalhad...  \n",
       "4                                      Fez isto, Dr. Ivins?  \n",
       "...                                                     ...  \n",
       "13262983                           Talvez um pouco cansada.  \n",
       "13262984       Não estás a comer a tua tarte de esparguete.  \n",
       "13262985  Acho que preciso que me emprestes algum dinheiro.  \n",
       "13262986                E a minha resposta, claro, é \"não\".  \n",
       "13262987  Há um grande concurso de tartes em Jonesville ...  \n",
       "\n",
       "[13262988 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffed01d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=3809310, line_no=4458377, pair_id=4458378, sent_pt_br='Poucas pessoas lhe causam tantos problemas e se safam.', sent_pt_pt='São poucos os que lhe causam tantos problemas e se safam.')\n",
      "Found 1 rows with pair_id 4458378.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in df.itertuples():\n",
    "    if row[2] == 4458378:\n",
    "        print(row)\n",
    "        count += 1\n",
    "print(f\"Found {count} rows with pair_id 4458378.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd773c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " line_no  pair_id                                                                    sent_pt_br                                                    sent_pt_pt\n",
      "12269158 12269159                                 A única pessoa que você já amou é você mesmo.                                  Só gostam de vocês próprios.\n",
      "12269159 12269160                                        Como não me amar? Terminar é doloroso.                                    - Como podemos não gostar?\n",
      "12269160 12269161                                                Por isso que eu nunca termino.                              - Acabar é duro. Eu nunca acabo.\n",
      "12269161 12269162 Por que machucar alguém quando pode deixar a situação se arrastar pra sempre? Para quê magoar alguém se podemos deixar a coisa arrastar-se?\n",
      "12269162 12269163                            Qual é, Vince. Você deve ter terminado com alguém.                              Já deves ter acabado com alguém.\n"
     ]
    }
   ],
   "source": [
    "show_context(df, 12269161)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80ac6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcdf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "con = duckdb.connect(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "# all user tables that live in the file itself (“main” schema)\n",
    "tables = con.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM   information_schema.tables\n",
    "    WHERE  table_schema = 'main'      -- skip temp tables & ATTACH-ed DBs\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(\"tables:\", [t[0] for t in tables])\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5a31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb, pathlib\n",
    "DB = pathlib.Path(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "ddl = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS subtitle_pairs_2 (\n",
    "    pair_id     BIGINT PRIMARY KEY,\n",
    "    line_no     BIGINT,\n",
    "    sent_pt_br  TEXT,\n",
    "    sent_pt_pt  TEXT,\n",
    "    score       DOUBLE           \n",
    ");\n",
    "\"\"\"\n",
    "with duckdb.connect(DB) as con:\n",
    "    con.execute(ddl)\n",
    "    con.execute(\"CHECKPOINT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b96cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz                 # pip install fuzzywuzzy python-Levenshtein\n",
    "import re, duckdb, pandas as pd, pathlib\n",
    "\n",
    "DB = pathlib.Path(\"../data/duckdb/subs.duckdb\")\n",
    "WEIGHT_TIME, WEIGHT_TEXT = 0.3, 0.7         # same as in your aligner\n",
    "\n",
    "# --- in-memory text cleaners -------------------------------------------\n",
    "tag_re   = re.compile(r'<[^>]+>|\\{[^}]+\\}')\n",
    "nl_re    = re.compile(r'\\s*\\n\\s*')\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = nl_re.sub(' ', s)          # eliminate_new_lines\n",
    "    s = tag_re.sub('', s).strip()  # strip <tags> or {tags}\n",
    "    return s\n",
    "\n",
    "def hungarian_like_score(a: str, b: str) -> float:\n",
    "    \"\"\"Score identical to your aligner when Δt = 0.\"\"\"\n",
    "    return WEIGHT_TIME + WEIGHT_TEXT * (fuzz.ratio(a, b) / 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a0eb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckdb.typing import VARCHAR, FLOAT   # import the constants\n",
    "\n",
    "def materialise_new_pairs():\n",
    "    \"\"\"Clean + score the unseen opus_moses rows and append to subtitle_pairs_2.\"\"\"\n",
    "    with duckdb.connect(DB) as con:\n",
    "        print(\"Connecting to\", DB)\n",
    "\n",
    "        # ── 1. how many new rows are there? ────────────────────────────\n",
    "        todo = con.execute(\"\"\"\n",
    "            SELECT COUNT(*) FROM opus_moses\n",
    "            WHERE pair_id NOT IN (SELECT pair_id FROM subtitle_pairs_2)\n",
    "        \"\"\").fetchone()[0]\n",
    "\n",
    "        if todo == 0:\n",
    "            print(\"✓ nothing new to process\")\n",
    "            return\n",
    "        print(f\"Found {todo:,} new rows to process\")\n",
    "\n",
    "        # ── 2. register the helpers for this session (DuckDB infers types) ─\n",
    "        con.create_function(\"clean_text\",           clean_text)\n",
    "        con.create_function(\"hungarian_like_score\", hungarian_like_score)\n",
    "\n",
    "        # ── 3. stream-insert, all work done inside DuckDB ──────────────\n",
    "        con.execute(\"\"\"\n",
    "            INSERT OR IGNORE INTO subtitle_pairs_2            \n",
    "            SELECT  line_no,\n",
    "                    pair_id,\n",
    "                    clean_text(sent_pt_br) AS sent_pt_br,\n",
    "                    clean_text(sent_pt_pt) AS sent_pt_pt,\n",
    "                    hungarian_like_score(\n",
    "                        clean_text(sent_pt_br),\n",
    "                        clean_text(sent_pt_pt)\n",
    "                    )                       AS score\n",
    "            FROM   opus_moses\n",
    "            WHERE  pair_id NOT IN (SELECT pair_id FROM subtitle_pairs_2)\n",
    "        \"\"\")\n",
    "\n",
    "        con.execute(\"PRAGMA force_checkpoint;\")     # folds & deletes .wal\n",
    "        print(f\"✓ inserted {todo:,} rows into subtitle_pairs_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c65a304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to ../data/duckdb/subs.duckdb\n",
      "Found 1,497,223 new rows to process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124daf31920346b0898584ccf6447acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ inserted 1,497,223 rows into subtitle_pairs_2\n"
     ]
    }
   ],
   "source": [
    "materialise_new_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977f1c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtitle_pairs_2 has 13262988 rows\n"
     ]
    }
   ],
   "source": [
    "with duckdb.connect(DB) as con:\n",
    "    n_rows = con.execute(\"SELECT COUNT(*) FROM subtitle_pairs_2\").fetchone()[0]\n",
    "\n",
    "print(\"subtitle_pairs_2 has\", n_rows, \"rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de5df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(DB_PATH, read_only=True)\n",
    "df2 = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM subtitle_pairs_2\n",
    "    LIMIT 500000\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65d4470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>line_no</th>\n",
       "      <th>sent_pt_br</th>\n",
       "      <th>sent_pt_pt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1667388</td>\n",
       "      <td>1667388</td>\n",
       "      <td>Mas ainda bem que está comigo.</td>\n",
       "      <td>Mas ainda bem que está comigo.</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1667389</td>\n",
       "      <td>1667389</td>\n",
       "      <td>Quando chegarmos ao campo de prisioneiros, vão...</td>\n",
       "      <td>Quando chegarmos ao campo de prisioneiros de g...</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1667391</td>\n",
       "      <td>1667391</td>\n",
       "      <td>Vou sentir a sua falta, Sargento.</td>\n",
       "      <td>Vou sentir a sua falta, Sargento.</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1667393</td>\n",
       "      <td>1667393</td>\n",
       "      <td>Não pare!</td>\n",
       "      <td>Não parem!</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1667396</td>\n",
       "      <td>1667396</td>\n",
       "      <td>- Ela está aqui?</td>\n",
       "      <td>- Ela está aqui? - Não.</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>9528214</td>\n",
       "      <td>9528215</td>\n",
       "      <td>Vá. Se não for, não funcionará.</td>\n",
       "      <td>Se não fores, a festa não começa.</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>9528215</td>\n",
       "      <td>9528216</td>\n",
       "      <td>Conto contigo. Ah...</td>\n",
       "      <td>Vai lá!</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>9528216</td>\n",
       "      <td>9528217</td>\n",
       "      <td>Os estúpidos nunca aprendem até que morrem.</td>\n",
       "      <td>Só a morte cura a estupidez!</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>9528217</td>\n",
       "      <td>9528218</td>\n",
       "      <td>Mh?</td>\n",
       "      <td>O Exército.</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>9528218</td>\n",
       "      <td>9528219</td>\n",
       "      <td>O maldito Exército não tem nada melhor para fa...</td>\n",
       "      <td>Que chatice!</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pair_id  line_no                                         sent_pt_br  \\\n",
       "0       1667388  1667388                     Mas ainda bem que está comigo.   \n",
       "1       1667389  1667389  Quando chegarmos ao campo de prisioneiros, vão...   \n",
       "2       1667391  1667391                  Vou sentir a sua falta, Sargento.   \n",
       "3       1667393  1667393                                          Não pare!   \n",
       "4       1667396  1667396                                   - Ela está aqui?   \n",
       "...         ...      ...                                                ...   \n",
       "499995  9528214  9528215                    Vá. Se não for, não funcionará.   \n",
       "499996  9528215  9528216                               Conto contigo. Ah...   \n",
       "499997  9528216  9528217        Os estúpidos nunca aprendem até que morrem.   \n",
       "499998  9528217  9528218                                                Mh?   \n",
       "499999  9528218  9528219  O maldito Exército não tem nada melhor para fa...   \n",
       "\n",
       "                                               sent_pt_pt  score  \n",
       "0                          Mas ainda bem que está comigo.  1.000  \n",
       "1       Quando chegarmos ao campo de prisioneiros de g...  0.916  \n",
       "2                       Vou sentir a sua falta, Sargento.  1.000  \n",
       "3                                              Não parem!  0.965  \n",
       "4                                 - Ela está aqui? - Não.  0.874  \n",
       "...                                                   ...    ...  \n",
       "499995                  Se não fores, a festa não começa.  0.734  \n",
       "499996                                            Vai lá!  0.405  \n",
       "499997                       Só a morte cura a estupidez!  0.517  \n",
       "499998                                        O Exército.  0.300  \n",
       "499999                                       Que chatice!  0.412  \n",
       "\n",
       "[500000 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d9484b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "12269161 not found in column 'pair_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mshow_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m12269161\u001b[39;49m\u001b[43m)\u001b[49m  \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mshow_context\u001b[39m\u001b[34m(df, id_value, id_col, n)\u001b[39m\n\u001b[32m     22\u001b[39m matches = df.index[df[id_col] == id_value]\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m matches.empty:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_value\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m not found in column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_col\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m i = matches[\u001b[32m0\u001b[39m]                       \u001b[38;5;66;03m# position of the match\u001b[39;00m\n\u001b[32m     27\u001b[39m start = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, i - n)                \u001b[38;5;66;03m# clamp to frame boundaries\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: 12269161 not found in column 'pair_id'"
     ]
    }
   ],
   "source": [
    "show_context(df, 12269161)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52fbfe0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5757daf28a284a3cb573d2a7d63accfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200,000 of the first 200,000 opus_moses rows match subtitle_pairs_2 after cleaning\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_N = 200_000              # adjust down if you still hit the limit\n",
    "\n",
    "with duckdb.connect(DB) as con:\n",
    "    con.create_function(\"clean_text\", clean_text)\n",
    "\n",
    "    equal_rows = con.execute(f\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM (\n",
    "            SELECT\n",
    "                clean_text(m.sent_pt_br) = s.sent_pt_br  AS br_ok,\n",
    "                clean_text(m.sent_pt_pt) = s.sent_pt_pt  AS pt_ok\n",
    "            FROM (\n",
    "                SELECT * FROM opus_moses\n",
    "                ORDER  BY line_no\n",
    "                LIMIT  {SAMPLE_N}\n",
    "            ) AS m\n",
    "            JOIN subtitle_pairs_2 AS s USING(pair_id)\n",
    "        )\n",
    "        WHERE br_ok AND pt_ok\n",
    "    \"\"\").fetchone()[0]\n",
    "\n",
    "print(f\"{equal_rows:,} of the first {SAMPLE_N:,} opus_moses rows match \"\n",
    "      \"subtitle_pairs_2 after cleaning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e5cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis (3.11.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
