{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105e4dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brazilian file : OpenSubtitles.pt-pt_BR.pt_BR\n",
      "European file  : OpenSubtitles.pt-pt_BR.pt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import duckdb, itertools, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path;  import duckdb, itertools, tqdm, mmap, math\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "# -------------------------------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------------------------------\n",
    "CACHE_DIR = Path(\"../data/opus_cache\")\n",
    "DB_PATH    = Path(\"../data/duckdb/subs.duckdb\")\n",
    "BATCH_SIZE = 50_000           # tune to your RAM/SSD speed\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "def find_files():\n",
    "    br = None\n",
    "    pt = None\n",
    "    for f in CACHE_DIR.iterdir():\n",
    "        fn = f.name\n",
    "        if fn.endswith(\".pt_BR\"):      # ← brazilian sentences\n",
    "            br = f\n",
    "        elif fn.endswith(\".pt\") and not fn.endswith(\".pt_BR\"):\n",
    "            # ends with '.pt' but NOT '.pt_BR' → european sentences\n",
    "            pt = f\n",
    "    if br is None or pt is None:\n",
    "        raise RuntimeError(\n",
    "            \"Could not uniquely identify the two files.\\n\"\n",
    "            \"Expected one file whose name ends with '.pt_BR' (br side) and\\n\"\n",
    "            \"one that ends with plain '.pt' (pt-PT side). Check CACHE_DIR!\"\n",
    "        )\n",
    "    return br, pt\n",
    "\n",
    "\n",
    "BR_PATH, PT_PATH = find_files()\n",
    "print(\"Brazilian file :\", BR_PATH.name)\n",
    "print(\"European file  :\", PT_PATH.name)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1) DuckDB schema  (sequence + table   → works in every DuckDB version)\n",
    "# -------------------------------------------------------------------------\n",
    "DDL = \"\"\"\n",
    "CREATE SEQUENCE IF NOT EXISTS seq_opus_moses START 1;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS opus_moses (\n",
    "    pair_id     BIGINT DEFAULT nextval('seq_opus_moses') PRIMARY KEY,\n",
    "    sent_pt_br  TEXT,\n",
    "    sent_pt_pt  TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "def get_connection():\n",
    "    DB_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    con = duckdb.connect(str(DB_PATH))\n",
    "    con.execute(DDL)\n",
    "    return con\n",
    "\n",
    "def insert_batch(con, rows):\n",
    "    con.executemany(\n",
    "        \"INSERT INTO opus_moses (sent_pt_br, sent_pt_pt) VALUES (?, ?)\",\n",
    "        rows\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 2) stream the two files line-by-line and insert\n",
    "# -------------------------------------------------------------------------\n",
    "def sentence_pairs():\n",
    "    with BR_PATH.open('r', encoding='utf-8') as br_f, \\\n",
    "         PT_PATH.open('r', encoding='utf-8') as pt_f:\n",
    "        for br_line, pt_line in zip(br_f, pt_f):\n",
    "            yield br_line.rstrip(\"\\n\"), pt_line.rstrip(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc21d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def show_context(df: pd.DataFrame,\n",
    "                 id_value,\n",
    "                 id_col: str = \"pair_id\",\n",
    "                 n: int = 2) -> None:\n",
    "    \"\"\"\n",
    "    Print *n* rows before and after the row whose `id_col` equals `id_value`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to search.\n",
    "    id_value : Any\n",
    "        The value to match in `id_col`.\n",
    "    id_col : str, default \"pair_id\"\n",
    "        Which column contains the identifier.\n",
    "    n : int, default 2\n",
    "        How many rows of context to show on each side.\n",
    "    \"\"\"\n",
    "    # find the positional index of the first matching row\n",
    "    matches = df.index[df[id_col] == id_value]\n",
    "    if matches.empty:\n",
    "        raise ValueError(f\"{id_value!r} not found in column {id_col!r}\")\n",
    "\n",
    "    i = matches[0]                       # position of the match\n",
    "    start = max(0, i - n)                # clamp to frame boundaries\n",
    "    end   = min(len(df), i + n + 1)\n",
    "\n",
    "    print(df.iloc[start:end].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dac0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import duckdb, pathlib, time\n",
    "\n",
    "# BAK = pathlib.Path(\"../data/duckdb/subs.duckdb.bak\").resolve()\n",
    "\n",
    "# con = duckdb.connect()                       # open an in-memory connection\n",
    "# con.execute(\"SET enable_progress_bar=true\")  # show progress for slow steps\n",
    "\n",
    "# # 1. attach the backup => DuckDB replays the 4 GB WAL (be patient: minutes)\n",
    "# t0 = time.time()\n",
    "# con.execute(f\"ATTACH '{BAK}' AS bak\")\n",
    "# print(\"WAL replay finished in\", round(time.time()-t0, 1), \"s\")\n",
    "\n",
    "# # 2. drop table, index & sequence that belong to opus_moses\n",
    "# con.execute(\"DROP TABLE IF EXISTS bak.opus_moses\")\n",
    "# con.execute(\"DROP SEQUENCE IF EXISTS bak.seq_opus_moses\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b562c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. checkpoint so the 4 GB WAL is folded into the main file  (now 0 B)\n",
    "# con.execute(\"PRAGMA force_checkpoint;\")\n",
    "# con.execute(\"CHECKPOINT;\")\n",
    "\n",
    "# # 4. vacuum to reclaim the table’s disk space\n",
    "# con.execute(\"VACUUM\")                        # rewrites the file compactly\n",
    "\n",
    "# # 5. detach and close\n",
    "# con.execute(\"DETACH bak\")\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a0b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import os, duckdb, time             # ‹-- getsize is in os.path\n",
    "\n",
    "# DB_PATH = Path(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "# print(\"DB:\", DB_PATH, \"size =\", os.path.getsize(DB_PATH)/1e6, \"MB\")\n",
    "# wal = DB_PATH.with_suffix(\".duckdb.wal\")\n",
    "# if wal.exists():\n",
    "#     print(\"WAL:\", wal, \"size =\", os.path.getsize(wal)/1e6, \"MB\")\n",
    "\n",
    "# t0 = time.time()\n",
    "# print(\"Connecting…\", flush=True)\n",
    "# con = duckdb.connect(DB_PATH)\n",
    "# print(\"Connected in\", round(time.time()-t0,2), \"s\")\n",
    "\n",
    "# con.execute(\"PRAGMA database_size;\").show()   # quick sanity check\n",
    "# con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45be9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con = duckdb.connect(\"../data/duckdb/subs.duckdb\")\n",
    "# con.execute(\"PRAGMA force_checkpoint;\")\n",
    "# con.execute(\"CHECKPOINT;\")\n",
    "# con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a8cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# paths to the two files you copied by hand\n",
    "# -------------------------------------------------------------------------\n",
    "CACHE_DIR = Path(\"../data/opus_cache\")\n",
    "BR_PATH   = CACHE_DIR / \"OpenSubtitles.pt-pt_BR.pt_BR\"\n",
    "PT_PATH   = CACHE_DIR / \"OpenSubtitles.pt-pt_BR.pt\"\n",
    "\n",
    "DB_PATH   = Path(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "BATCH_SIZE = 50_000        # change freely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769c72e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting lines in OpenSubtitles.pt-pt_BR.pt_BR\n",
      "Connecting to DuckDB database: ../data/duckdb/subs.duckdb\n",
      "Creating schema if not exists...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "701ac4e1014949a5afa928eab584112e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b57966734f44eef9e7e21ded1587398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema created or already exists.\n",
      "⏩ resuming after line 16,031,951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing:  33%|███▎      | 13849999/42508871 [37:37:47<77:51:53, 102.24pairs/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 85\u001b[39m\n\u001b[32m     82\u001b[39m     batch.append((ln, src, tgt))\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) >= BATCH_SIZE:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m         \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mINSERT OR IGNORE INTO opus_moses (line_no, sent_pt_br, sent_pt_pt) \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     87\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVALUES (?, ?, ?)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m         batch.clear()\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# tail\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen abc>:117\u001b[39m, in \u001b[36m__instancecheck__\u001b[39m\u001b[34m(cls, instance)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# helper – fast line-count (used only for nice tqdm total)\n",
    "# -------------------------------------------------------------------------\n",
    "def count_lines(fp: Path) -> int:\n",
    "    with fp.open('rb') as f, mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
    "        return mm.read().count(b'\\n')\n",
    "    \n",
    "print(\"Counting lines in\", BR_PATH.name)\n",
    "\n",
    "TOTAL_LINES = count_lines(BR_PATH)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# schema: de-dupe + unique guard + checkpoint\n",
    "# -------------------------------------------------------------------------\n",
    "DDL = \"\"\"\n",
    "CREATE SEQUENCE IF NOT EXISTS seq_opus_moses START 1;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS opus_moses (\n",
    "     line_no     BIGINT PRIMARY KEY,                 -- 1-based position\n",
    "     pair_id     BIGINT DEFAULT nextval('seq_opus_moses'),\n",
    "     sent_pt_br  TEXT,\n",
    "     sent_pt_pt  TEXT\n",
    ");\n",
    "\n",
    "-- 1) remove earlier duplicates, keep the lowest line_no\n",
    "DELETE FROM opus_moses\n",
    "USING (\n",
    "    SELECT line_no,\n",
    "           ROW_NUMBER() OVER (\n",
    "               PARTITION BY sent_pt_br, sent_pt_pt\n",
    "               ORDER BY line_no\n",
    "           ) AS dup\n",
    "    FROM opus_moses\n",
    ") AS tmp\n",
    "WHERE opus_moses.line_no = tmp.line_no\n",
    "  AND tmp.dup > 1;\n",
    "\n",
    "-- 2) future inserts may *try* to add a duplicate: stop them silently\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS uq_text_pair\n",
    "    ON opus_moses(sent_pt_br, sent_pt_pt);\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# open DB + run the DDL\n",
    "# -------------------------------------------------------------------------\n",
    "print(\"Connecting to DuckDB database:\", DB_PATH)\n",
    "con = duckdb.connect(DB_PATH)\n",
    "con.execute(\"SET checkpoint_threshold='100MB'\")\n",
    "con.execute(\"SET enable_progress_bar=true\")\n",
    "print(\"Creating schema if not exists...\")\n",
    "con.execute(DDL)\n",
    "print(\"Schema created or already exists.\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# find how many lines are already in the table  (= checkpoint)\n",
    "# -------------------------------------------------------------------------\n",
    "done = con.execute(\"SELECT MAX(line_no) FROM opus_moses\").fetchone()[0] or 0\n",
    "print(f\"⏩ resuming after line {done:,}\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# iterate over the *remaining* lines only\n",
    "# -------------------------------------------------------------------------\n",
    "def sentence_pairs(start_at: int):\n",
    "    with BR_PATH.open('r', encoding='utf-8') as br_f, \\\n",
    "         PT_PATH.open('r', encoding='utf-8') as pt_f:\n",
    "        # skip the already-imported prefix efficiently\n",
    "        for _ in range(start_at):\n",
    "            next(br_f); next(pt_f)\n",
    "\n",
    "        for ln, (br, pt) in enumerate(zip(br_f, pt_f), start_at + 1):\n",
    "            yield ln, br.rstrip(\"\\n\"), pt.rstrip(\"\\n\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# main load loop\n",
    "# -------------------------------------------------------------------------\n",
    "batch = []\n",
    "for ln, src, tgt in tqdm.tqdm(\n",
    "        sentence_pairs(done),\n",
    "        total=TOTAL_LINES - done,\n",
    "        desc=\"Importing\", unit=\"pairs\"):\n",
    "\n",
    "    batch.append((ln, src, tgt))\n",
    "\n",
    "    if len(batch) >= BATCH_SIZE:\n",
    "        con.executemany(\n",
    "            \"INSERT OR IGNORE INTO opus_moses (line_no, sent_pt_br, sent_pt_pt) \"\n",
    "            \"VALUES (?, ?, ?)\",\n",
    "            batch)\n",
    "        batch.clear()\n",
    "\n",
    "# tail\n",
    "if batch:\n",
    "    con.executemany(\n",
    "        \"INSERT OR IGNORE INTO opus_moses (line_no, sent_pt_br, sent_pt_pt) \"\n",
    "        \"VALUES (?, ?, ?)\",\n",
    "        batch)\n",
    "    \n",
    "con.execute(\"PRAGMA force_checkpoint;\")   # folds WAL pages into the DB\n",
    "con.execute(\"CHECKPOINT;\") \n",
    "\n",
    "con.close()\n",
    "print(\"✔ import complete; duplicates prevented going forward.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed365ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7044532",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(DB_PATH, read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215911de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = con.execute(\"\"\"\n",
    "    SELECT pair_id, sent_pt_br, sent_pt_pt, line_no\n",
    "    FROM opus_moses\n",
    "    ORDER BY pair_id\n",
    "    LIMIT 1000\n",
    "\"\"\").df()\n",
    "\n",
    "df_proc = con.execute(\"\"\"\n",
    "    SELECT pair_id, sent_pt_br, sent_pt_pt, score\n",
    "    FROM subtitle_pairs_2\n",
    "    WHERE score > 0.75 AND score < 0.9\n",
    "    LIMIT 1000\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480dfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>sent_pt_br</th>\n",
       "      <th>sent_pt_pt</th>\n",
       "      <th>line_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>o diretor mueller acaba de nomear nos um número de caso principal, investigações foi oficialmente dublado amerithrax, quemosenviou cartas receberam antraz de um laboratório americano, nós não estaríamos aqui se nós não tinha provas nos conduzindo de volta para usamriid,</td>\n",
       "      <td>Em episódios anteriores... O diretor Mueller atribuiu-nos um caso importante. Oficialmente, a investigação chama-se Amerithrax.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bruce ivins é o nosso melhor homem com antraz, então eu quero falar com ele, eles estão nos tratando como se fôssemos o inimigo, nós somos os heróis, a entrada tem que ser através do complexo de seu herói,</td>\n",
       "      <td>- Bruce Ivins é o perito em antraz. - Então quero falar com ele. Tratam-nos como o inimigo e somos os heróis.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>eu conheço a maioria dos americanos não estão prestando atenção, mas vocês tiveram sinais que o 11 de setembro iria acontecer, eagoravocênão consegueentender quem enviou essas cartas, então, em vez disso, você está assediando patriotas que trabalham duro como eu,</td>\n",
       "      <td>Temos de entrar através do complexo de herói dele. A maioria dos americanos não presta atenção, mas vocês tiveram sinais de que o 11 de Setembro ia acontecer. E agora não descobrem quem enviou as cartas.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bruce,vocêé considerando fazer fisicamente mal a alguém?</td>\n",
       "      <td>E, em vez disso, incomodam patriotas trabalhadores como eu. Bruce, está a pensar em magoar alguém?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>você fez isso, dr, ivins?</td>\n",
       "      <td>Fez isto, Dr. Ivins?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1010</td>\n",
       "      <td>Morro, de verdade, de vontades de ver-te.</td>\n",
       "      <td>Morro, de verdade, de vontades de ver-te.</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1011</td>\n",
       "      <td>Eu também cresço.</td>\n",
       "      <td>Eu também cresço.</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1012</td>\n",
       "      <td>Dizem que me estou tão grande que agora não me reconheceria.</td>\n",
       "      <td>Dizem que me estou tão grande que agora não me reconheceria.</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1013</td>\n",
       "      <td>Beijos.</td>\n",
       "      <td>Beijos.</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1014</td>\n",
       "      <td>Sua irmã peq... grande.</td>\n",
       "      <td>Sua irmã peq... grande.</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pair_id  \\\n",
       "0          1   \n",
       "1          2   \n",
       "2          3   \n",
       "3          4   \n",
       "4          5   \n",
       "..       ...   \n",
       "995     1010   \n",
       "996     1011   \n",
       "997     1012   \n",
       "998     1013   \n",
       "999     1014   \n",
       "\n",
       "                                                                                                                                                                                                                                                                         sent_pt_br  \\\n",
       "0    o diretor mueller acaba de nomear nos um número de caso principal, investigações foi oficialmente dublado amerithrax, quemosenviou cartas receberam antraz de um laboratório americano, nós não estaríamos aqui se nós não tinha provas nos conduzindo de volta para usamriid,   \n",
       "1                                                                     bruce ivins é o nosso melhor homem com antraz, então eu quero falar com ele, eles estão nos tratando como se fôssemos o inimigo, nós somos os heróis, a entrada tem que ser através do complexo de seu herói,   \n",
       "2           eu conheço a maioria dos americanos não estão prestando atenção, mas vocês tiveram sinais que o 11 de setembro iria acontecer, eagoravocênão consegueentender quem enviou essas cartas, então, em vez disso, você está assediando patriotas que trabalham duro como eu,   \n",
       "3                                                                                                                                                                                                                          bruce,vocêé considerando fazer fisicamente mal a alguém?   \n",
       "4                                                                                                                                                                                                                                                         você fez isso, dr, ivins?   \n",
       "..                                                                                                                                                                                                                                                                              ...   \n",
       "995                                                                                                                                                                                                                                       Morro, de verdade, de vontades de ver-te.   \n",
       "996                                                                                                                                                                                                                                                               Eu também cresço.   \n",
       "997                                                                                                                                                                                                                    Dizem que me estou tão grande que agora não me reconheceria.   \n",
       "998                                                                                                                                                                                                                                                                         Beijos.   \n",
       "999                                                                                                                                                                                                                                                         Sua irmã peq... grande.   \n",
       "\n",
       "                                                                                                                                                                                                      sent_pt_pt  \\\n",
       "0                                                                                Em episódios anteriores... O diretor Mueller atribuiu-nos um caso importante. Oficialmente, a investigação chama-se Amerithrax.   \n",
       "1                                                                                                  - Bruce Ivins é o perito em antraz. - Então quero falar com ele. Tratam-nos como o inimigo e somos os heróis.   \n",
       "2    Temos de entrar através do complexo de herói dele. A maioria dos americanos não presta atenção, mas vocês tiveram sinais de que o 11 de Setembro ia acontecer. E agora não descobrem quem enviou as cartas.   \n",
       "3                                                                                                             E, em vez disso, incomodam patriotas trabalhadores como eu. Bruce, está a pensar em magoar alguém?   \n",
       "4                                                                                                                                                                                           Fez isto, Dr. Ivins?   \n",
       "..                                                                                                                                                                                                           ...   \n",
       "995                                                                                                                                                                    Morro, de verdade, de vontades de ver-te.   \n",
       "996                                                                                                                                                                                            Eu também cresço.   \n",
       "997                                                                                                                                                 Dizem que me estou tão grande que agora não me reconheceria.   \n",
       "998                                                                                                                                                                                                      Beijos.   \n",
       "999                                                                                                                                                                                      Sua irmã peq... grande.   \n",
       "\n",
       "     line_no  \n",
       "0          1  \n",
       "1          2  \n",
       "2          3  \n",
       "3          4  \n",
       "4          5  \n",
       "..       ...  \n",
       "995     1010  \n",
       "996     1011  \n",
       "997     1012  \n",
       "998     1013  \n",
       "999     1014  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ba105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>sent_pt_br</th>\n",
       "      <th>sent_pt_pt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [pair_id, sent_pt_br, sent_pt_pt, score]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd773c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m show_context(\u001b[43mdf\u001b[49m, \u001b[32m12269161\u001b[39m)  \n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "show_context(df, 12269161)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcdf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tables: ['movies', 'opus_moses', 'ptbrvarid', 'subtitle_pairs', 'subtitle_pairs_2', 'test_data', 'train_data']\n",
      "['line_no', 'pair_id', 'sent_pt_br', 'sent_pt_pt']\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "con = duckdb.connect(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "# all user tables that live in the file itself (“main” schema)\n",
    "tables = con.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM   information_schema.tables\n",
    "    WHERE  table_schema = 'main'      -- skip temp tables & ATTACH-ed DBs\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(\"tables:\", [t[0] for t in tables])\n",
    "\n",
    "\n",
    "info = con.execute(\"PRAGMA table_info('opus_moses')\").df()\n",
    "print(info['name'].tolist())      # just the column names\n",
    "# or peek everything:\n",
    "# print(info)\n",
    "\n",
    "con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, duckdb, pathlib\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "DB = pathlib.Path(\"../data/duckdb/subs.duckdb\")\n",
    "WEIGHT_TIME, WEIGHT_TEXT = 0.3, 0.7  # keep your scoring surface\n",
    "\n",
    "# ---------- helpers ----------\n",
    "SPLIT_RE = re.compile(r'(?<=[\\.\\?\\!…])\\s+')\n",
    "tag_re   = re.compile(r'<[^>]+>|\\{[^}]+\\}')\n",
    "nl_re    = re.compile(r'\\s*\\n\\s*')\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not s: return \"\"\n",
    "    s = nl_re.sub(' ', s)\n",
    "    s = tag_re.sub('', s).strip()\n",
    "    return s\n",
    "\n",
    "def sim_token_set(a: str, b: str) -> float:\n",
    "    # length-aware damping for tiny fragments\n",
    "    def lw(x):\n",
    "        core = re.sub(r\"[\\W_]+\", \"\", x, flags=re.UNICODE)\n",
    "        L = len(core)\n",
    "        if L <= 6: return 0.25\n",
    "        if L >= 24: return 1.0\n",
    "        return 0.25 + (L - 6) / 18.0 * (1.0 - 0.25)\n",
    "    a, b = clean_text(a), clean_text(b)\n",
    "    base = fuzz.token_set_ratio(a, b) / 100.0\n",
    "    return base * lw(a) * lw(b)\n",
    "\n",
    "def score_text_only(a: str, b: str) -> float:\n",
    "    # your Δt=0 \"Hungarian-like\" score\n",
    "    return WEIGHT_TIME + WEIGHT_TEXT * (fuzz.ratio(clean_text(a), clean_text(b)) / 100.0)\n",
    "\n",
    "def split_tail_sentence(text: str):\n",
    "    parts = SPLIT_RE.split((text or \"\").strip())\n",
    "    if len(parts) < 2: return None, None\n",
    "    head = ' '.join(parts[:-1]).strip()\n",
    "    tail = parts[-1].strip()\n",
    "    if not head or not tail: return None, None\n",
    "    return head, tail\n",
    "\n",
    "def split_head_sentence(text: str):\n",
    "    parts = SPLIT_RE.split((text or \"\").strip())\n",
    "    if len(parts) < 2: return None, None\n",
    "    head = parts[0].strip()\n",
    "    rest = ' '.join(parts[1:]).strip()\n",
    "    if not head or not rest: return None, None\n",
    "    return head, rest\n",
    "\n",
    "# ---------- row-level transforms (pure Python) ----------\n",
    "def push_tails_forward_rows(rows, margin=0.05):\n",
    "    \"\"\"\n",
    "    Move last sentence of PT(i) to PT(i+1) when it helps vs BR(i), BR(i+1).\n",
    "    rows: list of {line_no, pair_id, sent_pt_br, sent_pt_pt}\n",
    "    \"\"\"\n",
    "    rows = [r.copy() for r in rows]\n",
    "    for i in range(len(rows) - 1):\n",
    "        pt_i, br_i     = rows[i][\"sent_pt_pt\"], rows[i][\"sent_pt_br\"]\n",
    "        pt_ip1, br_ip1 = rows[i+1][\"sent_pt_pt\"], rows[i+1][\"sent_pt_br\"]\n",
    "        head, tail = split_tail_sentence(pt_i)\n",
    "        if not tail:\n",
    "            continue\n",
    "        keep = sim_token_set(pt_i, br_i) + sim_token_set(pt_ip1, br_ip1)\n",
    "        pt_i2   = head\n",
    "        pt_ip12 = (tail + \" \" + (pt_ip1 or \"\")).strip()\n",
    "        move = sim_token_set(pt_i2, br_i) + sim_token_set(pt_ip12, br_ip1)\n",
    "        if move > keep + margin:\n",
    "            rows[i][\"sent_pt_pt\"]   = pt_i2\n",
    "            rows[i+1][\"sent_pt_pt\"] = pt_ip12\n",
    "    return rows\n",
    "\n",
    "def pull_heads_back_rows(rows, margin=0.05):\n",
    "    \"\"\"\n",
    "    Move first sentence of PT(i+1) back to the end of PT(i) when it helps.\n",
    "    \"\"\"\n",
    "    rows = [r.copy() for r in rows]\n",
    "    for i in range(len(rows) - 1):\n",
    "        pt_i, br_i     = rows[i][\"sent_pt_pt\"], rows[i][\"sent_pt_br\"]\n",
    "        pt_ip1, br_ip1 = rows[i+1][\"sent_pt_pt\"], rows[i+1][\"sent_pt_br\"]\n",
    "        head, rest = split_head_sentence(pt_ip1)\n",
    "        if not head:\n",
    "            continue\n",
    "        keep = sim_token_set(pt_i, br_i) + sim_token_set(pt_ip1, br_ip1)\n",
    "        pt_i2   = ((pt_i or \"\").rstrip() + (\" \" if pt_i else \"\") + head).strip()\n",
    "        pt_ip12 = rest\n",
    "        move = sim_token_set(pt_i2, br_i) + sim_token_set(pt_ip12, br_ip1)\n",
    "        if move > keep + margin:\n",
    "            rows[i][\"sent_pt_pt\"]   = pt_i2\n",
    "            rows[i+1][\"sent_pt_pt\"] = pt_ip12\n",
    "    return rows\n",
    "\n",
    "# ---------- PASS 1: forward-only (rebuild subtitle_pairs_2 from opus_moses) ----------\n",
    "def forward_pass_rebuild_pairs(margin=0.05):\n",
    "    with duckdb.connect(DB) as con:\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS subtitle_pairs_2(\n",
    "                line_no     INTEGER,\n",
    "                pair_id     BIGINT,\n",
    "                sent_pt_br  VARCHAR,\n",
    "                sent_pt_pt  VARCHAR,\n",
    "                score       DOUBLE\n",
    "            )\n",
    "        \"\"\")\n",
    "        con.execute(\"DELETE FROM subtitle_pairs_2;\")\n",
    "\n",
    "        df = con.execute(\"\"\"\n",
    "            SELECT line_no, pair_id, sent_pt_br, sent_pt_pt\n",
    "            FROM opus_moses\n",
    "            ORDER BY line_no\n",
    "        \"\"\").df()\n",
    "        if df.empty:\n",
    "            print(\"opus_moses is empty.\")\n",
    "            return\n",
    "\n",
    "        rows = [dict(zip(df.columns, r)) for r in df.itertuples(index=False, name=None)]\n",
    "        rows = push_tails_forward_rows(rows, margin=margin)\n",
    "\n",
    "        out = []\n",
    "        for r in rows:\n",
    "            br = clean_text(r[\"sent_pt_br\"])\n",
    "            pt = clean_text(r[\"sent_pt_pt\"])\n",
    "            sc = float(score_text_only(br, pt))\n",
    "            out.append((int(r[\"line_no\"]), int(r[\"pair_id\"]), br, pt, sc))\n",
    "\n",
    "        con.executemany(\"\"\"\n",
    "            INSERT INTO subtitle_pairs_2(line_no, pair_id, sent_pt_br, sent_pt_pt, score)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\", out)\n",
    "        con.execute(\"PRAGMA force_checkpoint;\")\n",
    "        print(f\"✓ forward pass wrote {len(out):,} rows to subtitle_pairs_2\")\n",
    "\n",
    "# ---------- PASS 2: backward-only (read/modify subtitle_pairs_2 in place) ----------\n",
    "def backward_pass_update_pairs(margin=0.05):\n",
    "    with duckdb.connect(DB) as con:\n",
    "        df = con.execute(\"\"\"\n",
    "            SELECT line_no, pair_id, sent_pt_br, sent_pt_pt\n",
    "            FROM subtitle_pairs_2\n",
    "            ORDER BY line_no\n",
    "        \"\"\").df()\n",
    "        if df.empty:\n",
    "            print(\"subtitle_pairs_2 is empty — run forward_pass_rebuild_pairs() first.\")\n",
    "            return\n",
    "\n",
    "        rows = [dict(zip(df.columns, r)) for r in df.itertuples(index=False, name=None)]\n",
    "        rows = pull_heads_back_rows(rows, margin=margin)\n",
    "\n",
    "        # rewrite table in one go (fast + atomic)\n",
    "        out = []\n",
    "        for r in rows:\n",
    "            br = clean_text(r[\"sent_pt_br\"])\n",
    "            pt = clean_text(r[\"sent_pt_pt\"])\n",
    "            sc = float(score_text_only(br, pt))\n",
    "            out.append((int(r[\"line_no\"]), int(r[\"pair_id\"]), br, pt, sc))\n",
    "\n",
    "        con.execute(\"BEGIN;\")\n",
    "        con.execute(\"DELETE FROM subtitle_pairs_2;\")\n",
    "        con.executemany(\"\"\"\n",
    "            INSERT INTO subtitle_pairs_2(line_no, pair_id, sent_pt_br, sent_pt_pt, score)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\", out)\n",
    "        con.execute(\"COMMIT;\")\n",
    "        con.execute(\"PRAGMA force_checkpoint;\")\n",
    "        print(f\"✓ backward pass updated {len(out):,} rows in subtitle_pairs_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e844eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ede5d3d43b4190b8fbc523293c8007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Do the forward pass once (rebuilds the table from opus_moses)\n",
    "forward_pass_rebuild_pairs(margin=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89228a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) If/when you want, run the backward pass on the saved result\n",
    "backward_pass_update_pairs(margin=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz                 # pip install fuzzywuzzy python-Levenshtein\n",
    "import re, duckdb, pandas as pd, pathlib\n",
    "\n",
    "DB = pathlib.Path(\"../data/duckdb/subs.duckdb\")\n",
    "WEIGHT_TIME, WEIGHT_TEXT = 0.3, 0.7         # same as in your aligner\n",
    "\n",
    "# --- in-memory text cleaners -------------------------------------------\n",
    "tag_re   = re.compile(r'<[^>]+>|\\{[^}]+\\}')\n",
    "nl_re    = re.compile(r'\\s*\\n\\s*')\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = nl_re.sub(' ', s)          # eliminate_new_lines\n",
    "    s = tag_re.sub('', s).strip()  # strip <tags> or {tags}\n",
    "    return s\n",
    "\n",
    "def hungarian_like_score(a: str, b: str) -> float:\n",
    "    \"\"\"Score identical to your aligner when Δt = 0.\"\"\"\n",
    "    return WEIGHT_TIME + WEIGHT_TEXT * (fuzz.ratio(a, b) / 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0eb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckdb.typing import VARCHAR, FLOAT   # import the constants\n",
    "\n",
    "def materialise_new_pairs():\n",
    "    \"\"\"Clean + score the unseen opus_moses rows and append to subtitle_pairs_2.\"\"\"\n",
    "    with duckdb.connect(DB) as con:\n",
    "        print(\"Connecting to\", DB)\n",
    "\n",
    "        # ── 1. how many new rows are there? ────────────────────────────\n",
    "        todo = con.execute(\"\"\"\n",
    "            SELECT COUNT(*) FROM opus_moses\n",
    "            WHERE pair_id NOT IN (SELECT pair_id FROM subtitle_pairs_2)\n",
    "        \"\"\").fetchone()[0]\n",
    "\n",
    "        if todo == 0:\n",
    "            print(\"✓ nothing new to process\")\n",
    "            return\n",
    "        print(f\"Found {todo:,} new rows to process\")\n",
    "\n",
    "        # ── 2. register the helpers for this session (DuckDB infers types) ─\n",
    "        con.create_function(\"clean_text\",           clean_text)\n",
    "        con.create_function(\"hungarian_like_score\", hungarian_like_score)\n",
    "\n",
    "        # ── 3. stream-insert, all work done inside DuckDB ──────────────\n",
    "        con.execute(\"\"\"\n",
    "            INSERT OR IGNORE INTO subtitle_pairs_2            \n",
    "            SELECT  line_no,\n",
    "                    pair_id,\n",
    "                    clean_text(sent_pt_br) AS sent_pt_br,\n",
    "                    clean_text(sent_pt_pt) AS sent_pt_pt,\n",
    "                    hungarian_like_score(\n",
    "                        clean_text(sent_pt_br),\n",
    "                        clean_text(sent_pt_pt)\n",
    "                    )                       AS score\n",
    "            FROM   opus_moses\n",
    "            WHERE  pair_id NOT IN (SELECT pair_id FROM subtitle_pairs_2)\n",
    "        \"\"\")\n",
    "\n",
    "        con.execute(\"PRAGMA force_checkpoint;\")     # folds & deletes .wal\n",
    "        print(f\"✓ inserted {todo:,} rows into subtitle_pairs_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65a304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to ../data/duckdb/subs.duckdb\n",
      "Found 1,497,223 new rows to process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124daf31920346b0898584ccf6447acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ inserted 1,497,223 rows into subtitle_pairs_2\n"
     ]
    }
   ],
   "source": [
    "materialise_new_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f1c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opus_moses has 13262988 rows\n"
     ]
    }
   ],
   "source": [
    "with duckdb.connect('../data/duckdb/subs.duckdb') as con:\n",
    "    n_rows = con.execute(\"SELECT COUNT(*) FROM opus_moses\").fetchone()[0]\n",
    "\n",
    "print(\"opus_moses has\", n_rows, \"rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(DB_PATH, read_only=True)\n",
    "df2 = con.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM subtitle_pairs_2\n",
    "    LIMIT 500000\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65d4470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>line_no</th>\n",
       "      <th>sent_pt_br</th>\n",
       "      <th>sent_pt_pt</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1667388</td>\n",
       "      <td>1667388</td>\n",
       "      <td>Mas ainda bem que está comigo.</td>\n",
       "      <td>Mas ainda bem que está comigo.</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1667389</td>\n",
       "      <td>1667389</td>\n",
       "      <td>Quando chegarmos ao campo de prisioneiros, vão...</td>\n",
       "      <td>Quando chegarmos ao campo de prisioneiros de g...</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1667391</td>\n",
       "      <td>1667391</td>\n",
       "      <td>Vou sentir a sua falta, Sargento.</td>\n",
       "      <td>Vou sentir a sua falta, Sargento.</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1667393</td>\n",
       "      <td>1667393</td>\n",
       "      <td>Não pare!</td>\n",
       "      <td>Não parem!</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1667396</td>\n",
       "      <td>1667396</td>\n",
       "      <td>- Ela está aqui?</td>\n",
       "      <td>- Ela está aqui? - Não.</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>9528214</td>\n",
       "      <td>9528215</td>\n",
       "      <td>Vá. Se não for, não funcionará.</td>\n",
       "      <td>Se não fores, a festa não começa.</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>9528215</td>\n",
       "      <td>9528216</td>\n",
       "      <td>Conto contigo. Ah...</td>\n",
       "      <td>Vai lá!</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>9528216</td>\n",
       "      <td>9528217</td>\n",
       "      <td>Os estúpidos nunca aprendem até que morrem.</td>\n",
       "      <td>Só a morte cura a estupidez!</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>9528217</td>\n",
       "      <td>9528218</td>\n",
       "      <td>Mh?</td>\n",
       "      <td>O Exército.</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>9528218</td>\n",
       "      <td>9528219</td>\n",
       "      <td>O maldito Exército não tem nada melhor para fa...</td>\n",
       "      <td>Que chatice!</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pair_id  line_no                                         sent_pt_br  \\\n",
       "0       1667388  1667388                     Mas ainda bem que está comigo.   \n",
       "1       1667389  1667389  Quando chegarmos ao campo de prisioneiros, vão...   \n",
       "2       1667391  1667391                  Vou sentir a sua falta, Sargento.   \n",
       "3       1667393  1667393                                          Não pare!   \n",
       "4       1667396  1667396                                   - Ela está aqui?   \n",
       "...         ...      ...                                                ...   \n",
       "499995  9528214  9528215                    Vá. Se não for, não funcionará.   \n",
       "499996  9528215  9528216                               Conto contigo. Ah...   \n",
       "499997  9528216  9528217        Os estúpidos nunca aprendem até que morrem.   \n",
       "499998  9528217  9528218                                                Mh?   \n",
       "499999  9528218  9528219  O maldito Exército não tem nada melhor para fa...   \n",
       "\n",
       "                                               sent_pt_pt  score  \n",
       "0                          Mas ainda bem que está comigo.  1.000  \n",
       "1       Quando chegarmos ao campo de prisioneiros de g...  0.916  \n",
       "2                       Vou sentir a sua falta, Sargento.  1.000  \n",
       "3                                              Não parem!  0.965  \n",
       "4                                 - Ela está aqui? - Não.  0.874  \n",
       "...                                                   ...    ...  \n",
       "499995                  Se não fores, a festa não começa.  0.734  \n",
       "499996                                            Vai lá!  0.405  \n",
       "499997                       Só a morte cura a estupidez!  0.517  \n",
       "499998                                        O Exército.  0.300  \n",
       "499999                                       Que chatice!  0.412  \n",
       "\n",
       "[500000 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9484b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "12269161 not found in column 'pair_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mshow_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m12269161\u001b[39;49m\u001b[43m)\u001b[49m  \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mshow_context\u001b[39m\u001b[34m(df, id_value, id_col, n)\u001b[39m\n\u001b[32m     22\u001b[39m matches = df.index[df[id_col] == id_value]\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m matches.empty:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_value\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m not found in column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mid_col\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m i = matches[\u001b[32m0\u001b[39m]                       \u001b[38;5;66;03m# position of the match\u001b[39;00m\n\u001b[32m     27\u001b[39m start = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, i - n)                \u001b[38;5;66;03m# clamp to frame boundaries\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: 12269161 not found in column 'pair_id'"
     ]
    }
   ],
   "source": [
    "show_context(df, 12269161)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fbfe0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5757daf28a284a3cb573d2a7d63accfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200,000 of the first 200,000 opus_moses rows match subtitle_pairs_2 after cleaning\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_N = 200_000              # adjust down if you still hit the limit\n",
    "\n",
    "with duckdb.connect(DB) as con:\n",
    "    con.create_function(\"clean_text\", clean_text)\n",
    "\n",
    "    equal_rows = con.execute(f\"\"\"\n",
    "        SELECT COUNT(*)\n",
    "        FROM (\n",
    "            SELECT\n",
    "                clean_text(m.sent_pt_br) = s.sent_pt_br  AS br_ok,\n",
    "                clean_text(m.sent_pt_pt) = s.sent_pt_pt  AS pt_ok\n",
    "            FROM (\n",
    "                SELECT * FROM opus_moses\n",
    "                ORDER  BY line_no\n",
    "                LIMIT  {SAMPLE_N}\n",
    "            ) AS m\n",
    "            JOIN subtitle_pairs_2 AS s USING(pair_id)\n",
    "        )\n",
    "        WHERE br_ok AND pt_ok\n",
    "    \"\"\").fetchone()[0]\n",
    "\n",
    "print(f\"{equal_rows:,} of the first {SAMPLE_N:,} opus_moses rows match \"\n",
    "      \"subtitle_pairs_2 after cleaning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e5cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
