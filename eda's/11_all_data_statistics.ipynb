{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "917517e1",
   "metadata": {},
   "source": [
    "**// IMPORTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26642730",
   "metadata": {},
   "source": [
    "**// CONFIGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80079db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb, pathlib\n",
    "\n",
    "PROJECT_DB_PATH = pathlib.Path(\"../data/duckdb/subs_project.duckdb\")\n",
    "SOURCE_DB_PATH  = pathlib.Path(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "con = duckdb.connect(PROJECT_DB_PATH.as_posix())\n",
    "con.execute(\"PRAGMA threads=1;\")\n",
    "con.execute(\"PRAGMA preserve_insertion_order=false;\")\n",
    "con.execute(\"PRAGMA memory_limit='4GB';\")  # <-- increase this if your machine has the RAM\n",
    "con.execute(\"PRAGMA temp_directory='/tmp/duckdb_tmp';\")  # make sure this dir exists\n",
    "\n",
    "dbl = con.execute(\"PRAGMA database_list\").df()\n",
    "if not (dbl[\"name\"] == \"src\").any():\n",
    "    con.execute(f\"ATTACH '{SOURCE_DB_PATH.as_posix()}' AS src;\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b4205",
   "metadata": {},
   "source": [
    "**// MAIN CODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139ae584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(con.execute(\"SELECT COUNT(*) FROM train_data;\").df())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20391754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_stats_for(\n",
    "    table: str,\n",
    "    col: str,\n",
    "    split: str | None = None,\n",
    "    dataset: str | None = None,\n",
    "):\n",
    "    where_clauses = [f\"{col} IS NOT NULL\"]\n",
    "    if split is not None:\n",
    "        where_clauses.append(f\"split = '{split}'\")\n",
    "    if dataset is not None:\n",
    "        where_clauses.append(f\"dataset = '{dataset}'\")\n",
    "    where_sql = \" AND \".join(where_clauses)\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "            COUNT(*)                                   AS n,\n",
    "            AVG(LENGTH({col}))                         AS mean,\n",
    "            MIN(LENGTH({col}))                         AS min,\n",
    "            MAX(LENGTH({col}))                         AS max,\n",
    "            approx_quantile(LENGTH({col}), 0.50)       AS median,\n",
    "            approx_quantile(LENGTH({col}), 0.90)       AS p90,\n",
    "            approx_quantile(LENGTH({col}), 0.95)       AS p95,\n",
    "            approx_quantile(LENGTH({col}), 0.99)       AS p99\n",
    "        FROM {table}\n",
    "        WHERE {where_sql};\n",
    "    \"\"\"\n",
    "    return con.execute(sql).df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d92eaac",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Query interrupted",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# train vs valid, all datasets\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_br  = \u001b[43mchar_stats_for\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext_pt_br\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.assign(split=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, side=\u001b[33m\"\u001b[39m\u001b[33mpt_br\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m train_pt  = char_stats_for(\u001b[33m\"\u001b[39m\u001b[33mtrain_data\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext_pt_pt\u001b[39m\u001b[33m\"\u001b[39m, split=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m).assign(split=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, side=\u001b[33m\"\u001b[39m\u001b[33mpt_pt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m valid_br  = char_stats_for(\u001b[33m\"\u001b[39m\u001b[33mtrain_data\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtext_pt_br\u001b[39m\u001b[33m\"\u001b[39m, split=\u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m).assign(split=\u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m, side=\u001b[33m\"\u001b[39m\u001b[33mpt_br\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mchar_stats_for\u001b[39m\u001b[34m(table, col, split, dataset)\u001b[39m\n\u001b[32m     12\u001b[39m where_sql = \u001b[33m\"\u001b[39m\u001b[33m AND \u001b[39m\u001b[33m\"\u001b[39m.join(where_clauses)\n\u001b[32m     14\u001b[39m sql = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m    SELECT\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m        COUNT(*)                                   AS n,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m \u001b[33m    WHERE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhere_sql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m;\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m)\u001b[49m.df()\n",
      "\u001b[31mRuntimeError\u001b[39m: Query interrupted"
     ]
    }
   ],
   "source": [
    "# train vs valid, all datasets\n",
    "train_br  = char_stats_for(\"train_data\", \"text_pt_br\", split=\"train\").assign(split=\"train\", side=\"pt_br\")\n",
    "train_pt  = char_stats_for(\"train_data\", \"text_pt_pt\", split=\"train\").assign(split=\"train\", side=\"pt_pt\")\n",
    "\n",
    "valid_br  = char_stats_for(\"train_data\", \"text_pt_br\", split=\"valid\").assign(split=\"valid\", side=\"pt_br\")\n",
    "valid_pt  = char_stats_for(\"train_data\", \"text_pt_pt\", split=\"valid\").assign(split=\"valid\", side=\"pt_pt\")\n",
    "\n",
    "test_br   = char_stats_for(\"test_data\",  \"text_pt_br\").assign(split=\"test\", side=\"pt_br\")\n",
    "test_pt   = char_stats_for(\"test_data\",  \"text_pt_pt\").assign(split=\"test\", side=\"pt_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e1f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>p90</th>\n",
       "      <th>p95</th>\n",
       "      <th>p99</th>\n",
       "      <th>split</th>\n",
       "      <th>side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10684022</td>\n",
       "      <td>52.870606</td>\n",
       "      <td>1</td>\n",
       "      <td>4087</td>\n",
       "      <td>32</td>\n",
       "      <td>86</td>\n",
       "      <td>128</td>\n",
       "      <td>482</td>\n",
       "      <td>train</td>\n",
       "      <td>pt_br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12976311</td>\n",
       "      <td>136.413371</td>\n",
       "      <td>1</td>\n",
       "      <td>4523</td>\n",
       "      <td>39</td>\n",
       "      <td>413</td>\n",
       "      <td>679</td>\n",
       "      <td>1158</td>\n",
       "      <td>train</td>\n",
       "      <td>pt_pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3330</td>\n",
       "      <td>452.204805</td>\n",
       "      <td>27</td>\n",
       "      <td>3805</td>\n",
       "      <td>389</td>\n",
       "      <td>725</td>\n",
       "      <td>861</td>\n",
       "      <td>1398</td>\n",
       "      <td>valid</td>\n",
       "      <td>pt_br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26390</td>\n",
       "      <td>515.622205</td>\n",
       "      <td>35</td>\n",
       "      <td>4045</td>\n",
       "      <td>409</td>\n",
       "      <td>974</td>\n",
       "      <td>1149</td>\n",
       "      <td>1456</td>\n",
       "      <td>valid</td>\n",
       "      <td>pt_pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3288</td>\n",
       "      <td>162.168796</td>\n",
       "      <td>4</td>\n",
       "      <td>3109</td>\n",
       "      <td>138</td>\n",
       "      <td>276</td>\n",
       "      <td>347</td>\n",
       "      <td>603</td>\n",
       "      <td>test</td>\n",
       "      <td>pt_br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3888</td>\n",
       "      <td>278.699588</td>\n",
       "      <td>5</td>\n",
       "      <td>3947</td>\n",
       "      <td>189</td>\n",
       "      <td>622</td>\n",
       "      <td>899</td>\n",
       "      <td>1293</td>\n",
       "      <td>test</td>\n",
       "      <td>pt_pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n        mean  min   max  median  p90   p95   p99  split   side\n",
       "0  10684022   52.870606    1  4087      32   86   128   482  train  pt_br\n",
       "1  12976311  136.413371    1  4523      39  413   679  1158  train  pt_pt\n",
       "2      3330  452.204805   27  3805     389  725   861  1398  valid  pt_br\n",
       "3     26390  515.622205   35  4045     409  974  1149  1456  valid  pt_pt\n",
       "4      3288  162.168796    4  3109     138  276   347   603   test  pt_br\n",
       "5      3888  278.699588    5  3947     189  622   899  1293   test  pt_pt"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "char_len_stats = pd.concat([train_br, train_pt, valid_br, valid_pt, test_br, test_pt], ignore_index=True)\n",
    "char_len_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13367c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898fc0004eca47a19c73756e1115829d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fcba817e854addbc026b950bb1eb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_br_not_null</th>\n",
       "      <th>n_pt_not_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>FRMT</td>\n",
       "      <td>3915</td>\n",
       "      <td>2503.0</td>\n",
       "      <td>2505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>OpenSubs</td>\n",
       "      <td>10347883</td>\n",
       "      <td>10347883.0</td>\n",
       "      <td>10347883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>PtBrVarId</td>\n",
       "      <td>2959559</td>\n",
       "      <td>333636.0</td>\n",
       "      <td>2625923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>valid</td>\n",
       "      <td>FRMT</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>valid</td>\n",
       "      <td>PtBrVarId</td>\n",
       "      <td>29680</td>\n",
       "      <td>3310.0</td>\n",
       "      <td>26370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>FRMT</td>\n",
       "      <td>3987</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>2614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>Gold</td>\n",
       "      <td>500</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>PtBrVarId</td>\n",
       "      <td>1450</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1274.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split    dataset    n_rows  n_br_not_null  n_pt_not_null\n",
       "0  train       FRMT      3915         2503.0         2505.0\n",
       "1  train   OpenSubs  10347883     10347883.0     10347883.0\n",
       "2  train  PtBrVarId   2959559       333636.0      2625923.0\n",
       "3  valid       FRMT        20           20.0           20.0\n",
       "4  valid  PtBrVarId     29680         3310.0        26370.0\n",
       "5   test       FRMT      3987         2612.0         2614.0\n",
       "6   test       Gold       500          500.0            0.0\n",
       "7   test  PtBrVarId      1450          176.0         1274.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data has both train + valid, distinguished by `split`\n",
    "per_dataset_train = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        split,               -- 'train' or 'valid'\n",
    "        dataset,\n",
    "        COUNT(*)                          AS n_rows,\n",
    "        SUM(text_pt_br IS NOT NULL)       AS n_br_not_null,\n",
    "        SUM(text_pt_pt IS NOT NULL)       AS n_pt_not_null\n",
    "    FROM train_data\n",
    "    GROUP BY split, dataset\n",
    "    ORDER BY split, dataset;\n",
    "\"\"\").df()\n",
    "\n",
    "# test_data usually only has test, so we inject split='test'\n",
    "per_dataset_test = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        'test' AS split,\n",
    "        dataset,\n",
    "        COUNT(*)                          AS n_rows,\n",
    "        SUM(text_pt_br IS NOT NULL)       AS n_br_not_null,\n",
    "        SUM(text_pt_pt IS NOT NULL)       AS n_pt_not_null\n",
    "    FROM test_data\n",
    "    GROUP BY dataset\n",
    "    ORDER BY dataset;\n",
    "\"\"\").df()\n",
    "\n",
    "import pandas as pd\n",
    "per_dataset = pd.concat([per_dataset_train, per_dataset_test], ignore_index=True)\n",
    "per_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4df0324",
   "metadata": {},
   "source": [
    "**// TOKENS COUNT PER SPLIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    if text is None:\n",
    "        return 0\n",
    "    # no padding, no truncation, no special tokens -> dataset \"raw\" token length\n",
    "    return len(tokenizer(text, add_special_tokens=False).input_ids)\n",
    "\n",
    "\n",
    "\n",
    "def token_stats_for_table(table: str, has_split_col: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    table: 'train_data' or 'test_data'\n",
    "    has_split_col: True for train_data, False for test_data (we inject split='test')\n",
    "    \"\"\"\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "        SELECT split, text_pt_br, text_pt_pt\n",
    "        FROM {table}\n",
    "        WHERE text_pt_br IS NOT NULL OR text_pt_pt IS NOT NULL\n",
    "    \"\"\"\n",
    "    rel = con.execute(sql)\n",
    "\n",
    "    # stats[split] = dict with counters\n",
    "    stats = defaultdict(lambda: {\n",
    "        \"n_rows\": 0,\n",
    "        \"tokens_br\": 0,\n",
    "        \"tokens_pt\": 0,\n",
    "    })\n",
    "\n",
    "    BATCH_SIZE = 50_000 # adjust if you want more/less speed vs memory\n",
    "\n",
    "    while True:\n",
    "        rows = rel.fetchmany(BATCH_SIZE)  # list of tuples (split, text_pt_br, text_pt_pt)\n",
    "        if not rows:\n",
    "            break\n",
    "\n",
    "        for split, text_pt_br, text_pt_pt in rows:\n",
    "            s = stats[split]\n",
    "            s[\"n_rows\"] += 1\n",
    "            if text_pt_br is not None:\n",
    "                s[\"tokens_br\"] += count_tokens(text_pt_br)\n",
    "            if text_pt_pt is not None:\n",
    "                s[\"tokens_pt\"] += count_tokens(text_pt_pt)\n",
    "\n",
    "    # convert to DataFrame\n",
    "    out_rows = []\n",
    "    for split, s in stats.items():\n",
    "        n = s[\"n_rows\"] or 1  # avoid division by zero\n",
    "        out_rows.append({\n",
    "            \"split\": split,\n",
    "            \"n_rows\": s[\"n_rows\"],\n",
    "            \"total_tokens_pt_br\": s[\"tokens_br\"],\n",
    "            \"mean_tokens_pt_br\": s[\"tokens_br\"] / n,\n",
    "            \"total_tokens_pt_pt\": s[\"tokens_pt\"],\n",
    "            \"mean_tokens_pt_pt\": s[\"tokens_pt\"] / n,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "train_valid_stats = token_stats_for_table(\"train_data\", has_split_col=True)\n",
    "test_stats        = token_stats_for_table(\"test_data\",  has_split_col=False)\n",
    "\n",
    "token_len_stats = pd.concat([train_valid_stats, test_stats], ignore_index=True) \\\n",
    "                    .sort_values(\"split\")\n",
    "\n",
    "token_len_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0af813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate PtBrVarId tables/views: ['ptbr_processed_v', 'ptbr_split_assign_v', 'ptbr_unique_v', 'ptbrvarid_processed_v', 'ptbrvarid_seen', 'ptbrvarid_split_v', 'ptbrvarid_text_v', 'ptbrvarid_v', 'ptbrvid_repaired_v']\n",
      "\n",
      "ptbr_processed_v columns (first 25): ['dataset', 'domain', 'split', 'label', 'text_pt_br', 'text_pt_pt'] ...\n",
      "\n",
      "ptbr_split_assign_v columns (first 25): ['split', 'label', 'domain', 'text_pt_br', 'text_pt_pt'] ...\n",
      "\n",
      "ptbr_unique_v columns (first 25): ['label', 'domain', 'text_pt_br', 'text_pt_pt'] ...\n",
      "\n",
      "ptbrvarid_processed_v columns (first 25): ['dataset', 'domain', 'split', 'label', 'text_pt_br', 'text_pt_pt'] ...\n",
      "\n",
      "ptbrvarid_seen columns (first 25): ['key'] ...\n",
      "\n",
      "ptbrvarid_split_v columns (first 25): ['split', 'label', 'text_pt_br', 'text_pt_pt'] ...\n",
      "\n",
      "ptbrvarid_text_v columns (first 25): ['label', 'text'] ...\n",
      "\n",
      "ptbrvarid_v columns (first 25): ['split', 'label', 'text_pt_br', 'text_pt_pt'] ...\n",
      "\n",
      "ptbrvid_repaired_v columns (first 25): ['dataset', 'domain', 'label', 'text_pt_br', 'text_pt_pt'] ...\n",
      "\n",
      "Using table/view: ptbr_processed_v | split column: split | label column: label\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e004b8db5a6440596f5792a74e3a055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>label</th>\n",
       "      <th>n</th>\n",
       "      <th>total</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>pt-PT</td>\n",
       "      <td>2654577</td>\n",
       "      <td>2991728</td>\n",
       "      <td>88.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>pt-BR</td>\n",
       "      <td>337151</td>\n",
       "      <td>2991728</td>\n",
       "      <td>11.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  label        n    total    pct\n",
       "0  train  pt-PT  2654577  2991728  88.73\n",
       "1  train  pt-BR   337151  2991728  11.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>pt-BR</th>\n",
       "      <th>pt-PT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>337151.0</td>\n",
       "      <td>2654577.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label     pt-BR      pt-PT\n",
       "split                     \n",
       "train  337151.0  2654577.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>pt-BR</th>\n",
       "      <th>pt-PT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>11.27</td>\n",
       "      <td>88.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label  pt-BR  pt-PT\n",
       "split              \n",
       "train  11.27  88.73"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "con.execute(\"SET preserve_insertion_order=false;\")\n",
    "con.execute(\"SET threads=1;\")\n",
    "\n",
    "# --- 1) Find candidate tables/views ---\n",
    "tables = con.execute(\"SHOW TABLES\").fetchdf()[\"name\"].tolist()\n",
    "pt_tables = [t for t in tables if (\"ptbr\" in t.lower()) or (\"vid\" in t.lower())]\n",
    "print(\"Candidate PtBrVarId tables/views:\", pt_tables)\n",
    "\n",
    "# --- 2) Inspect columns to find a usable table ---\n",
    "def get_cols(t):\n",
    "    return con.execute(f\"DESCRIBE {t}\").fetchdf()[\"column_name\"].str.lower().tolist()\n",
    "\n",
    "label_candidates = [\"label\", \"variety\", \"variant\", \"gold_label\", \"target\"]\n",
    "split_candidates = [\"split\", \"data_split\"]\n",
    "\n",
    "chosen = None\n",
    "chosen_label = None\n",
    "chosen_split = None\n",
    "\n",
    "for t in pt_tables:\n",
    "    cols = get_cols(t)\n",
    "    label_col = next((c for c in label_candidates if c in cols), None)\n",
    "    split_col = next((c for c in split_candidates if c in cols), None)\n",
    "    print(f\"\\n{t} columns (first 25):\", cols[:25], \"...\")\n",
    "    if label_col and split_col and chosen is None:\n",
    "        chosen, chosen_label, chosen_split = t, label_col, split_col\n",
    "\n",
    "if chosen is None:\n",
    "    raise RuntimeError(\n",
    "        \"Couldn't auto-find a PtBrVarId table with both a split column and a label column.\\n\"\n",
    "        \"From the printed tables above, pick the right table and set chosen/chosen_label/chosen_split manually.\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nUsing table/view: {chosen} | split column: {chosen_split} | label column: {chosen_label}\")\n",
    "\n",
    "# --- 3) Compute label distribution per split (cheap query) ---\n",
    "q = f\"\"\"\n",
    "SELECT\n",
    "  {chosen_split} AS split,\n",
    "  {chosen_label} AS label,\n",
    "  COUNT(*) AS n\n",
    "FROM {chosen}\n",
    "WHERE {chosen_label} IS NOT NULL\n",
    "  AND {chosen_split} IN ('train','valid','test')\n",
    "GROUP BY 1, 2\n",
    "ORDER BY split, n DESC\n",
    "\"\"\"\n",
    "df = con.execute(q).fetchdf()\n",
    "\n",
    "# Totals + %\n",
    "totals = df.groupby(\"split\", as_index=False)[\"n\"].sum().rename(columns={\"n\": \"total\"})\n",
    "df = df.merge(totals, on=\"split\", how=\"left\")\n",
    "df[\"pct\"] = (100.0 * df[\"n\"] / df[\"total\"]).round(2)\n",
    "\n",
    "display(df)\n",
    "display(df.pivot_table(index=\"split\", columns=\"label\", values=\"n\", fill_value=0))\n",
    "display(df.pivot_table(index=\"split\", columns=\"label\", values=\"pct\", fill_value=0.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57125c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
