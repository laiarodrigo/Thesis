{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "917517e1",
   "metadata": {},
   "source": [
    "**// IMPORTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26642730",
   "metadata": {},
   "source": [
    "**// CONFIGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80079db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb, pathlib\n",
    "\n",
    "PROJECT_DB_PATH = pathlib.Path(\"../data/duckdb/subs_project.duckdb\")\n",
    "SOURCE_DB_PATH  = pathlib.Path(\"../data/duckdb/subs.duckdb\")\n",
    "\n",
    "con = duckdb.connect(PROJECT_DB_PATH.as_posix())\n",
    "con.execute(\"PRAGMA threads=1;\")\n",
    "con.execute(\"PRAGMA preserve_insertion_order=false;\")\n",
    "con.execute(\"PRAGMA memory_limit='4GB';\")  # <-- increase this if your machine has the RAM\n",
    "con.execute(\"PRAGMA temp_directory='/tmp/duckdb_tmp';\")  # make sure this dir exists\n",
    "\n",
    "dbl = con.execute(\"PRAGMA database_list\").df()\n",
    "if not (dbl[\"name\"] == \"src\").any():\n",
    "    con.execute(f\"ATTACH '{SOURCE_DB_PATH.as_posix()}' AS src;\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b4205",
   "metadata": {},
   "source": [
    "**// MAIN CODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139ae584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(con.execute(\"SELECT COUNT(*) FROM train_data;\").df())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20391754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_stats_for(\n",
    "    table: str,\n",
    "    col: str,\n",
    "    split: str | None = None,\n",
    "    dataset: str | None = None,\n",
    "):\n",
    "    where_clauses = [f\"{col} IS NOT NULL\"]\n",
    "    if split is not None:\n",
    "        where_clauses.append(f\"split = '{split}'\")\n",
    "    if dataset is not None:\n",
    "        where_clauses.append(f\"dataset = '{dataset}'\")\n",
    "    where_sql = \" AND \".join(where_clauses)\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "            COUNT(*)                                   AS n,\n",
    "            AVG(LENGTH({col}))                         AS mean,\n",
    "            MIN(LENGTH({col}))                         AS min,\n",
    "            MAX(LENGTH({col}))                         AS max,\n",
    "            approx_quantile(LENGTH({col}), 0.50)       AS median,\n",
    "            approx_quantile(LENGTH({col}), 0.90)       AS p90,\n",
    "            approx_quantile(LENGTH({col}), 0.95)       AS p95,\n",
    "            approx_quantile(LENGTH({col}), 0.99)       AS p99\n",
    "        FROM {table}\n",
    "        WHERE {where_sql};\n",
    "    \"\"\"\n",
    "    return con.execute(sql).df()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d92eaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000d6e0f2b4c40cb97e9904e169d7ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63b095e81b547eebea14678b509ea19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7438f0d1cb44f53863d5ef08700987a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c493bbcdb34a0e8b439de4a048ec16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51f34fff96c4be986265cad2f824cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92a47097fb74426960814dcf1184855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train vs valid, all datasets\n",
    "train_br  = char_stats_for(\"train_data\", \"text_pt_br\", split=\"train\").assign(split=\"train\", side=\"pt_br\")\n",
    "train_pt  = char_stats_for(\"train_data\", \"text_pt_pt\", split=\"train\").assign(split=\"train\", side=\"pt_pt\")\n",
    "\n",
    "valid_br  = char_stats_for(\"train_data\", \"text_pt_br\", split=\"valid\").assign(split=\"valid\", side=\"pt_br\")\n",
    "valid_pt  = char_stats_for(\"train_data\", \"text_pt_pt\", split=\"valid\").assign(split=\"valid\", side=\"pt_pt\")\n",
    "\n",
    "test_br   = char_stats_for(\"test_data\",  \"text_pt_br\").assign(split=\"test\", side=\"pt_br\")\n",
    "test_pt   = char_stats_for(\"test_data\",  \"text_pt_pt\").assign(split=\"test\", side=\"pt_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "767e1f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>p90</th>\n",
       "      <th>p95</th>\n",
       "      <th>p99</th>\n",
       "      <th>split</th>\n",
       "      <th>side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10684022</td>\n",
       "      <td>52.870606</td>\n",
       "      <td>1</td>\n",
       "      <td>4087</td>\n",
       "      <td>32</td>\n",
       "      <td>86</td>\n",
       "      <td>128</td>\n",
       "      <td>482</td>\n",
       "      <td>train</td>\n",
       "      <td>pt_br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12976311</td>\n",
       "      <td>136.413371</td>\n",
       "      <td>1</td>\n",
       "      <td>4523</td>\n",
       "      <td>39</td>\n",
       "      <td>413</td>\n",
       "      <td>679</td>\n",
       "      <td>1158</td>\n",
       "      <td>train</td>\n",
       "      <td>pt_pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3330</td>\n",
       "      <td>452.204805</td>\n",
       "      <td>27</td>\n",
       "      <td>3805</td>\n",
       "      <td>389</td>\n",
       "      <td>725</td>\n",
       "      <td>861</td>\n",
       "      <td>1398</td>\n",
       "      <td>valid</td>\n",
       "      <td>pt_br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26390</td>\n",
       "      <td>515.622205</td>\n",
       "      <td>35</td>\n",
       "      <td>4045</td>\n",
       "      <td>409</td>\n",
       "      <td>974</td>\n",
       "      <td>1149</td>\n",
       "      <td>1456</td>\n",
       "      <td>valid</td>\n",
       "      <td>pt_pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3288</td>\n",
       "      <td>162.168796</td>\n",
       "      <td>4</td>\n",
       "      <td>3109</td>\n",
       "      <td>138</td>\n",
       "      <td>276</td>\n",
       "      <td>347</td>\n",
       "      <td>603</td>\n",
       "      <td>test</td>\n",
       "      <td>pt_br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3888</td>\n",
       "      <td>278.699588</td>\n",
       "      <td>5</td>\n",
       "      <td>3947</td>\n",
       "      <td>189</td>\n",
       "      <td>622</td>\n",
       "      <td>899</td>\n",
       "      <td>1293</td>\n",
       "      <td>test</td>\n",
       "      <td>pt_pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n        mean  min   max  median  p90   p95   p99  split   side\n",
       "0  10684022   52.870606    1  4087      32   86   128   482  train  pt_br\n",
       "1  12976311  136.413371    1  4523      39  413   679  1158  train  pt_pt\n",
       "2      3330  452.204805   27  3805     389  725   861  1398  valid  pt_br\n",
       "3     26390  515.622205   35  4045     409  974  1149  1456  valid  pt_pt\n",
       "4      3288  162.168796    4  3109     138  276   347   603   test  pt_br\n",
       "5      3888  278.699588    5  3947     189  622   899  1293   test  pt_pt"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "char_len_stats = pd.concat([train_br, train_pt, valid_br, valid_pt, test_br, test_pt], ignore_index=True)\n",
    "char_len_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13367c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898fc0004eca47a19c73756e1115829d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fcba817e854addbc026b950bb1eb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>dataset</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_br_not_null</th>\n",
       "      <th>n_pt_not_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>FRMT</td>\n",
       "      <td>3915</td>\n",
       "      <td>2503.0</td>\n",
       "      <td>2505.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>OpenSubs</td>\n",
       "      <td>10347883</td>\n",
       "      <td>10347883.0</td>\n",
       "      <td>10347883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>PtBrVarId</td>\n",
       "      <td>2959559</td>\n",
       "      <td>333636.0</td>\n",
       "      <td>2625923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>valid</td>\n",
       "      <td>FRMT</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>valid</td>\n",
       "      <td>PtBrVarId</td>\n",
       "      <td>29680</td>\n",
       "      <td>3310.0</td>\n",
       "      <td>26370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>FRMT</td>\n",
       "      <td>3987</td>\n",
       "      <td>2612.0</td>\n",
       "      <td>2614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>Gold</td>\n",
       "      <td>500</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>PtBrVarId</td>\n",
       "      <td>1450</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1274.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split    dataset    n_rows  n_br_not_null  n_pt_not_null\n",
       "0  train       FRMT      3915         2503.0         2505.0\n",
       "1  train   OpenSubs  10347883     10347883.0     10347883.0\n",
       "2  train  PtBrVarId   2959559       333636.0      2625923.0\n",
       "3  valid       FRMT        20           20.0           20.0\n",
       "4  valid  PtBrVarId     29680         3310.0        26370.0\n",
       "5   test       FRMT      3987         2612.0         2614.0\n",
       "6   test       Gold       500          500.0            0.0\n",
       "7   test  PtBrVarId      1450          176.0         1274.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data has both train + valid, distinguished by `split`\n",
    "per_dataset_train = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        split,               -- 'train' or 'valid'\n",
    "        dataset,\n",
    "        COUNT(*)                          AS n_rows,\n",
    "        SUM(text_pt_br IS NOT NULL)       AS n_br_not_null,\n",
    "        SUM(text_pt_pt IS NOT NULL)       AS n_pt_not_null\n",
    "    FROM train_data\n",
    "    GROUP BY split, dataset\n",
    "    ORDER BY split, dataset;\n",
    "\"\"\").df()\n",
    "\n",
    "# test_data usually only has test, so we inject split='test'\n",
    "per_dataset_test = con.execute(\"\"\"\n",
    "    SELECT\n",
    "        'test' AS split,\n",
    "        dataset,\n",
    "        COUNT(*)                          AS n_rows,\n",
    "        SUM(text_pt_br IS NOT NULL)       AS n_br_not_null,\n",
    "        SUM(text_pt_pt IS NOT NULL)       AS n_pt_not_null\n",
    "    FROM test_data\n",
    "    GROUP BY dataset\n",
    "    ORDER BY dataset;\n",
    "\"\"\").df()\n",
    "\n",
    "import pandas as pd\n",
    "per_dataset = pd.concat([per_dataset_train, per_dataset_test], ignore_index=True)\n",
    "per_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4df0324",
   "metadata": {},
   "source": [
    "**// TOKENS COUNT PER SPLIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    if text is None:\n",
    "        return 0\n",
    "    # no padding, no truncation, no special tokens -> dataset \"raw\" token length\n",
    "    return len(tokenizer(text, add_special_tokens=False).input_ids)\n",
    "\n",
    "\n",
    "\n",
    "def token_stats_for_table(table: str, has_split_col: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    table: 'train_data' or 'test_data'\n",
    "    has_split_col: True for train_data, False for test_data (we inject split='test')\n",
    "    \"\"\"\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "        SELECT split, text_pt_br, text_pt_pt\n",
    "        FROM {table}\n",
    "        WHERE text_pt_br IS NOT NULL OR text_pt_pt IS NOT NULL\n",
    "    \"\"\"\n",
    "    rel = con.execute(sql)\n",
    "\n",
    "    # stats[split] = dict with counters\n",
    "    stats = defaultdict(lambda: {\n",
    "        \"n_rows\": 0,\n",
    "        \"tokens_br\": 0,\n",
    "        \"tokens_pt\": 0,\n",
    "    })\n",
    "\n",
    "    BATCH_SIZE = 50_000 # adjust if you want more/less speed vs memory\n",
    "\n",
    "    while True:\n",
    "        rows = rel.fetchmany(BATCH_SIZE)  # list of tuples (split, text_pt_br, text_pt_pt)\n",
    "        if not rows:\n",
    "            break\n",
    "\n",
    "        for split, text_pt_br, text_pt_pt in rows:\n",
    "            s = stats[split]\n",
    "            s[\"n_rows\"] += 1\n",
    "            if text_pt_br is not None:\n",
    "                s[\"tokens_br\"] += count_tokens(text_pt_br)\n",
    "            if text_pt_pt is not None:\n",
    "                s[\"tokens_pt\"] += count_tokens(text_pt_pt)\n",
    "\n",
    "    # convert to DataFrame\n",
    "    out_rows = []\n",
    "    for split, s in stats.items():\n",
    "        n = s[\"n_rows\"] or 1  # avoid division by zero\n",
    "        out_rows.append({\n",
    "            \"split\": split,\n",
    "            \"n_rows\": s[\"n_rows\"],\n",
    "            \"total_tokens_pt_br\": s[\"tokens_br\"],\n",
    "            \"mean_tokens_pt_br\": s[\"tokens_br\"] / n,\n",
    "            \"total_tokens_pt_pt\": s[\"tokens_pt\"],\n",
    "            \"mean_tokens_pt_pt\": s[\"tokens_pt\"] / n,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(out_rows)\n",
    "\n",
    "train_valid_stats = token_stats_for_table(\"train_data\", has_split_col=True)\n",
    "test_stats        = token_stats_for_table(\"test_data\",  has_split_col=False)\n",
    "\n",
    "token_len_stats = pd.concat([train_valid_stats, test_stats], ignore_index=True) \\\n",
    "                    .sort_values(\"split\")\n",
    "\n",
    "token_len_stats\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
